{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import io\n",
    "from config import api_key_prism\n",
    "from collections import OrderedDict\n",
    "from pandas.io.json import json_normalize  \n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## API request from Prism\n",
    "\n",
    "url = 'https://vtfsmghslrepo02.fsm.northwestern.edu/api/records'\n",
    "\n",
    "# records = 100\n",
    "# size = 100 - total\n",
    "\n",
    "params={'size': 100, \n",
    "        'offset': 100,\n",
    "#         'page': 2, \n",
    "        'status': \n",
    "        'published', \n",
    "        'sort': 'bestmatch', \n",
    "        'all_versions': 'false', \n",
    "        'access_token': api_key_prism\n",
    "       }\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "\n",
    "print(response.url)\n",
    "print(response.status_code)\n",
    "\n",
    "response_json = response.json()['hits']\n",
    "total = response.json()['hits']['total']\n",
    "\n",
    "print(json.dumps(response_json, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response_json['hits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# ## Starting URL\n",
    "# url = 'https://vtfsmghslrepo02.fsm.northwestern.edu/api/records'\n",
    "# offset = 0\n",
    "# size = 100\n",
    "# records=[]\n",
    "\n",
    "\n",
    "# while True: \n",
    "    \n",
    "#     ## Python time method sleep() suspends execution for the given number of seconds \n",
    "#     time.sleep(0.1) \n",
    "    \n",
    "#     print(\"------\")\n",
    "    \n",
    "#     params={'size': size, \n",
    "#         'offset': offset,\n",
    "# #         'page': 2, \n",
    "#         'status': \n",
    "#         'published', \n",
    "#         'sort': 'bestmatch', \n",
    "#         'all_versions': 'false', \n",
    "#         'access_token': api_key_prism\n",
    "#        }\n",
    "\n",
    "#     response = requests.get(url, params=params)\n",
    "    \n",
    "#     print(response.url)\n",
    "#     print(response.status_code)\n",
    "    \n",
    "#     response_json = response.json()['hits']\n",
    "# #     total = response.json()['hits']['total']\n",
    "\n",
    "    \n",
    "#     ## Did we find any records? \n",
    "#     if len(response_json[\"hits\"]) == 0:\n",
    "#         ## If no, then break and break the while loop.\n",
    "#         break\n",
    "    \n",
    "#     ## If we did find records, add them to the list and move on to next offset\n",
    "#     records.extend(response_json[\"hits\"])\n",
    "#     offset= offset + 100\n",
    "   \n",
    "# ## Pros: very flexible\n",
    "# ## Cons: extra request, doesn't really listen to the API for the next URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = response.json()['hits']\n",
    "print(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(records)\n",
    "print(type(records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prism_item_df = pd.DataFrame.from_dict(json_normalize(response_json, meta=['hits']))\n",
    "# prism_item_df.head()\n",
    "\n",
    "prism_item_df = pd.json_normalize(records, max_level = 1)\n",
    "prism_item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_hits_nest = prism_item_df.apply(lambda x: pd.Series(x['hits']),axis=1).stack().reset_index(level=1, drop=True).to_frame()\n",
    "remove_hits_nest.rename(columns = {0:'data'}, inplace = True)\n",
    "remove_hits_nest.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_json(nested_json, exclude=['']):\n",
    "    \"\"\"Flatten json object with nested keys into a single level.\n",
    "        Args:\n",
    "            nested_json: A nested json object.\n",
    "            exclude: Keys to exclude from output.\n",
    "        Returns:\n",
    "            The flattened json object if successful, None otherwise.\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "\n",
    "    def flatten(x, name='', exclude=exclude):\n",
    "        if type(x) is dict:\n",
    "            for a in x:\n",
    "                if a not in exclude: flatten(x[a], name + a + '_')\n",
    "        elif type(x) is list:\n",
    "            i = 0\n",
    "            for a in x:\n",
    "                flatten(a, name + str(i) + '_')\n",
    "                i += 1\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    "\n",
    "    flatten(nested_json)\n",
    "    return out\n",
    "\n",
    "## https://stackoverflow.com/questions/52795561/flattening-nested-json-in-pandas-data-frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame([flatten_json(x) for x in remove_hits_nest['data']])\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export file to excel, without the Pandas index, but with the header\n",
    "\n",
    "final_df.to_excel(\"outputs/final_df.xlsx\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Remove NESTS manually\n",
    "\n",
    "# remove_0_nest = pd.concat([remove_hits_nest.drop(['data'], axis=1), remove_hits_nest['data'].apply(pd.Series)], axis=1, join=\"outer\")\n",
    "\n",
    "# ## REMOVE PIDS NESTS\n",
    "# remove_pids_nest_1 = pd.concat([remove_0_nest.drop(['pids'], axis=1), remove_0_nest['pids'].apply(pd.Series)], axis=1, join=\"outer\")\n",
    "# remove_pids_nest_1.rename(columns = {'oai':'pids.oai'}, inplace = True)\n",
    "\n",
    "# remove_pids_nest_2 = pd.concat([remove_pids_nest_1.drop(['pids.oai'], axis=1), remove_pids_nest_1['pids.oai'].apply(pd.Series)], axis=1, join=\"outer\")\n",
    "# remove_pids_nest_2.rename(columns = {'identifier':'pids.oai.identifer', 'provider': 'pids.oai.provider'}, inplace = True)\n",
    "\n",
    "\n",
    "# ## REMOVE PARENT NESTS\n",
    "# remove_parent_nest_1 = pd.concat([remove_pids_nest_2.drop(['parent'], axis=1), remove_pids_nest_2['parent'].apply(pd.Series)], axis=1, join=\"outer\")\n",
    "# remove_parent_nest_1.rename(columns = {'id':'parent.id', 'communities':'parent.communities'}, inplace = True)\n",
    "\n",
    "# remove_parent_nest_2 = pd.concat([remove_parent_nest_1.drop(['parent.communities'], axis=1), remove_parent_nest_1['parent.communities'].apply(pd.Series)], axis=1, join=\"outer\")\n",
    "# remove_parent_nest_2.rename(columns = {'ids':'parent.communities.ids', 'default':'parent.communities.default'}, inplace = True)\n",
    "\n",
    "# remove_access_nest_1 = pd.concat([remove_parent_nest_1.drop(['access'], axis=1), remove_parent_nest_1['access'].apply(pd.Series)], axis=1, join=\"outer\")\n",
    "# remove_access_nest_1.rename(columns = {'status':'access.status', 'files':'access.files', 'embargo':'access.embargo', 'record':'access.record'}, inplace = True)\n",
    "\n",
    "\n",
    "# remove_parent_nest_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
