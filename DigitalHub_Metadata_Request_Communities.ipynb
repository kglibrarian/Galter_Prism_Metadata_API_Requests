{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775cd13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "from requests.exceptions import HTTPError\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import io\n",
    "from config import api_key_prism\n",
    "from collections import OrderedDict\n",
    "from pandas.io.json import json_normalize  \n",
    "import time \n",
    "import urllib.request\n",
    "from pprint import pprint\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741df69d",
   "metadata": {},
   "source": [
    "### Get Collections Data from DigitalHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15600a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Upload a .csv DigitalHub Collections that will become Prism Communities\n",
    "\n",
    "digitalhub_community_path = \"data/2022_08-01 DigitalHub Collection Migration Plan_Communities Only.csv\"\n",
    "\n",
    "## Read the CSV file and store into Pandas DataFrame \n",
    "digitalhub_community_df = pd.read_csv(digitalhub_community_path , encoding = \"ISO-8859-1\", na_values=['NULL', '<NA>'])\n",
    "\n",
    "## encoding = \"ISO-8859-1\", na_values=['NULL', '<NA>']\n",
    "\n",
    "#Change the column names to lower case with underscore for spaces\n",
    "digitalhub_community_df.columns =  digitalhub_community_df.columns.str.strip().str.lower().str.replace(\" \", \"_\").str.replace(\"(\",\"\").str.replace(\")\",\"\")\n",
    "digitalhub_community_df.head()\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d018d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract a the Series for \"dh_id\" and transform into a list\n",
    "\n",
    "digitalhub_community_series = digitalhub_community_df[\"dh_id\"]\n",
    "digitalhub_community_list = digitalhub_community_series.tolist()\n",
    "\n",
    "print(len(digitalhub_community_list))\n",
    "print(digitalhub_community_list)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda08590",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop through list of DigitalHub Collection URLS (i.e. Communities) and use the urllib.request to get the json data\n",
    "## test_list = ['2cc92425-b656-47ea-a3b4-825405ee6088', 'a86e1412-d72c-4cae-b8ca-16fd834cb128','fc389d13-2430-409b-82fd-a4b26613d350']\n",
    "\n",
    "multi_digitalhub_community_list = []\n",
    "digitalhub_community_problem_list = []\n",
    "api_response_list = []\n",
    "\n",
    "for item in digitalhub_community_list:\n",
    "    try:\n",
    "\n",
    "        with urllib.request.urlopen(f\"https://digitalhub.northwestern.edu/collections/{item}.json\" ) as url:\n",
    "            single_digitalhub_community_dict = json.loads(url.read().decode())\n",
    "            multi_digitalhub_community_list.append(single_digitalhub_community_dict)\n",
    "            print(item)\n",
    "        time.sleep(1)\n",
    "\n",
    "        ## Create api response dict\n",
    "        api_response_dict = {}\n",
    "\n",
    "        ## Add UUID to api response dict\n",
    "        api_response_dict['dh_id'] = item\n",
    "\n",
    "    except urllib.error.HTTPError as http_err:\n",
    "        print(item)\n",
    "        digitalhub_community_problem_list.append(item)\n",
    "        print(f'HTTP error occurred: {http_err}')  # Python 3.6\n",
    "                \n",
    "        ## Add err to api response dict\n",
    "        api_response_dict['Response'] = http_err\n",
    "        api_response_list.append(api_response_dict)        \n",
    "\n",
    "    except urllib.error.URLError as url_err:\n",
    "        print(item)\n",
    "        digitalhub_community_problem_list.append(item)\n",
    "        print(f'URL error occurred: {url_err}. ', 'Exiting the loop!')  # Python 3.6\n",
    "        \n",
    "        ## Add err to api response dict\n",
    "        api_response_dict['Response'] = url_err\n",
    "        api_response_list.append(api_response_dict)              \n",
    "\n",
    "    except json.JSONDecodeError as json_err:\n",
    "        print(item)\n",
    "        digitalhub_community_problem_list.append(item)\n",
    "        print(f'JSON Decode error occurred: {json_err}. ', 'Poorly formed JSON.')  # Python 3.6\n",
    "        \n",
    "        ## Add err to api response dict\n",
    "        api_response_dict['Response'] = json_err\n",
    "        api_response_list.append(api_response_dict)  \n",
    "        \n",
    "    except Exception as err:\n",
    "        print(item)\n",
    "        digitalhub_community_problem_list.append(item)\n",
    "        print(f'Other error occurred: {err}. ')  # Python 3.6\n",
    "        \n",
    "        ## Add err to api response dict\n",
    "        api_response_dict['Response'] = err\n",
    "        api_response_list.append(api_response_dict)          \n",
    "       \n",
    "    else:\n",
    "        success_message = \"Success\"\n",
    "        print(success_message)\n",
    "\n",
    "        ## Add success message to api response dict\n",
    "        api_response_dict['Response'] = success_message\n",
    "        api_response_list.append(api_response_dict)\n",
    "\n",
    "\n",
    "## Resources\n",
    "## https://docs.python.org/3/library/urllib.request.html\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1050a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspect the results of the API response list of the URL Query for DigitalHub Collections \n",
    "\n",
    "api_response_df = pd.DataFrame(api_response_list)\n",
    "# api_response_df.head(50)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2cefce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export file to excel, with the Pandas index, and with the headers\n",
    "\n",
    "api_response_df.to_excel(\"outputs/digitalhub_api_response_df.xlsx\", header=True)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f65ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspect the results of the URL Query for DigitalHub Collections that will become communities in Prism\n",
    "\n",
    "# print(multi_digitalhub_community_list)\n",
    "print(digitalhub_community_problem_list)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85ab464",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a dataframe from DigitalHub json for DigitalHub Collections that will become communities in Prism\n",
    "\n",
    "digitalhub_community_df = pd.DataFrame.from_dict(json_normalize(multi_digitalhub_community_list, max_level=1))\n",
    "# digitalhub_community_df.head(10)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71427688",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Upload .txt files of the problem Community json metadata\n",
    "\n",
    "## Problem with: cfda59b0-7d3c-4aa7-9f5e-53665849d624\n",
    "northwesternelements_path = r\"data\\community\\northwesternelements.txt\"\n",
    "\n",
    "##problem with: ce39f2be-9a64-4717-973b-ff531c2a93ee\n",
    "communicationbridge_path = r\"data\\community\\communicationbridge.txt\"\n",
    "\n",
    "## Problem with: f2bf6e1d-0e32-4ce2-a52e-bb0522d5708d\n",
    "nucatsgrantsrepository_path = r\"data\\community\\nucatsgrantsrepository.txt\"\n",
    "\n",
    "## Problem with: 97a2913d-45b8-458c-82eb-5111a94b6c9f\n",
    "preventionmethodology_path = r\"data\\community\\preventionmethodology.txt\"\n",
    "\n",
    "problem_dict_list = []\n",
    "\n",
    "path_list = [northwesternelements_path, communicationbridge_path,nucatsgrantsrepository_path, preventionmethodology_path]\n",
    "for path in path_list: \n",
    "#     print(path)\n",
    "    with open(path) as f:\n",
    "        problem_dict = json.load(f)\n",
    "        problem_dict_list.append(problem_dict)\n",
    "    \n",
    "# print(problem_dict_list)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7e381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_df = pd.DataFrame.from_dict(json_normalize(problem_dict_list, max_level=1))\n",
    "# problem_df.head()\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000ceca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate the DigitalHub Community Dataframe to the problem_df\n",
    "\n",
    "digitalhub_community_df = pd.concat([digitalhub_community_df, problem_df], axis=0)\n",
    "digitalhub_community_df.reset_index(inplace=True, drop=True) \n",
    "# digitalhub_community_df.head(10)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa0de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NOT NEEDED FOR RUN THROUGH DIGITALHUB, just for adding to \"desired\" organization for migrating to Prism\n",
    "\n",
    "## Create some communities\n",
    "\n",
    "added_communities_df = pd.DataFrame([{'Multi-page?':[], \n",
    "                                      'Title':'Galter Library Audio-Video Archives',\n",
    "                                      'Keyword':[], \n",
    "                                      'Resource type(s)':[], \n",
    "                                      'Rights':[],\n",
    "                                      'Creator':[], \n",
    "                                      'Contributor':[], \n",
    "                                      'Description':[], \n",
    "                                      'Abstract':[],\n",
    "                                      'Original Bibliographic Citation':[], \n",
    "                                      'Related URL':[], \n",
    "                                      'Publisher':[],\n",
    "                                      'Date Created':[], \n",
    "                                      'Original Identifier':[], \n",
    "                                      'Language':[], \n",
    "                                      'Subject: MESH':[],\n",
    "                                      'Subject: LCSH':[], \n",
    "                                      'Subject: Geographic Name':[], \n",
    "                                      'Subject: Name':[],\n",
    "                                      'Location':[],\n",
    "                                      'Digital Origin':[], \n",
    "                                      'Id':'galter-library-audio-video-archives',                                           \n",
    "                                      'uri':[],\n",
    "                                      'members':[{'Id':'cece380d-4dee-4e4e-aa97-28cb1d4f6b19'},\n",
    "                                                  {'Id':'student-life'},\n",
    "                                                  {'Id':'paul-de-kruif-interviews'},\n",
    "                                                  {'Id':'b1546649-c60e-441b-9042-ec7a27adaf66', 'DOI': '10.18131/G3P44X'}]                                                 \n",
    "                                     },\n",
    "                                     {'Multi-page?':[], \n",
    "                                      'Title':'History of Feinberg School of Medicine',                                               \n",
    "                                      'Keyword':[], \n",
    "                                      'Resource type(s)':[], \n",
    "                                      'Rights':[],\n",
    "                                      'Creator':[], \n",
    "                                      'Contributor':[], \n",
    "                                      'Description':[], \n",
    "                                      'Abstract':[],\n",
    "                                      'Original Bibliographic Citation':[], \n",
    "                                      'Related URL':[], \n",
    "                                      'Publisher':[],\n",
    "                                      'Date Created':[], \n",
    "                                      'Original Identifier':[], \n",
    "                                      'Language':[], \n",
    "                                      'Subject: MESH':[],\n",
    "                                      'Subject: LCSH':[], \n",
    "                                      'Subject: Geographic Name':[], \n",
    "                                      'Subject: Name':[],\n",
    "                                      'Location':[],\n",
    "                                      'Digital Origin':[], \n",
    "                                      'Id':'history-of-feinberg-school-of-medicine',                                                                            \n",
    "                                      'uri':[],\n",
    "                                      'members':[{'Id':'2f75r807r'}, # Special Collections: art \n",
    "                                                  {'Id':'areybook', 'DOI': '10.18131/G39735'}, #Northwestern University Medical School 1859-1979\n",
    "                                                  {'Id':'5712m6524'}, #Special Collections: photos from the vault\n",
    "                                                  {'Id': '6d56zw644', 'DOI': 'doi:10.18131/G3S01B'},\n",
    "                                                  {'Id': '01d4023f-da66-45c4-8987-af7badda959a', 'DOI': 'doi:10.18131/G3BG7D'},\n",
    "                                                  {'Id': 'h702q639b', 'DOI':'doi:10.18131/G3P88T'},\n",
    "                                                  {'Id': '47429913s','DOI': '10.18131/G39G6Q'},\n",
    "                                                  {'Id': '6m311p28w','DOI': '10.18131/G3K01G'},\n",
    "                                                  {'Id': 'pr76f340k','DOI': '10.18131/G3F590'},\n",
    "                                                  {'Id': 'f670ed27-d344-4cb1-aa34-e3339f2992d5','DOI': '10.18131/G3889G'},\n",
    "                                                  {'Id': 'aa85a365-c493-42cf-922c-21ab24407a1e','DOI': '10.18131/G3K605'},\n",
    "                                                  {'Id': 'c85b38a8-e367-4ef4-8c0a-35a94c479dc6','DOI': '10.18131/G3FG8Q'},\n",
    "                                                  {'Id': 'e13451f1-01ff-4462-acbf-2a87eb2312e2','DOI': '10.18131/G3WP5P'},\n",
    "                                                  {'Id': '3f4ac3b8-6c05-4b4d-978e-f5ab7388743b','DOI': '10.18131/G3461H'},\n",
    "                                                  {'Id': '7d8b5c55-9d80-40a5-992f-7bbadd466d5b','DOI': '10.18131/G38W3D'},\n",
    "                                                  {'Id': '506cbdca-cd9d-43fd-9be7-4b1b912782e5','DOI': '10.18131/G3XW4P'},\n",
    "                                                  {'Id': '695a2e0f-428f-41ea-acd8-66486a1e292b','DOI': '10.18131/G38P6G'},\n",
    "                                                  {'Id': 'ae887507-5e30-4129-91c2-dda6f8e5f944','DOI': '10.18131/G3DK72'},\n",
    "                                                  {'Id': '9cc06089-1a82-4378-ad19-b93dbbd402cb','DOI': '10.18131/G3P726'},\n",
    "                                                  {'Id': '9f47bff1-33b4-4d63-88b2-75aab10b84bb','DOI': '10.18131/G3CP6D'},\n",
    "                                                  {'Id': '0a5c7f42-7b10-443e-985a-b773a04e15ba','DOI': '10.18131/G3T31P'},\n",
    "                                                  {'Id': 'd520d291-a3ab-431c-a992-6a931779ff31','DOI': '10.18131/G37W33'},\n",
    "                                                  {'Id': 'b6971153-c8bd-4f03-9917-d68659a89784','DOI': '10.18131/G3390V'},\n",
    "                                                  {'Id': '752b7c7f-ec96-4635-af07-34d4b36dac78','DOI': '10.18131/G3VC9S'},\n",
    "                                                  {'Id': '3f4ac3b8-6c05-4b4d-978e-f5ab7388743b','DOI': '10.18131/G3461H'},\n",
    "                                                  {'Id': '9k41zd48h','DOI': '10.18131/G32P4V'}]\n",
    "                                     },\n",
    "                                     { 'Multi-page?':[], \n",
    "                                      'Title':'Researchers Collections',\n",
    "                                      'Keyword':[], \n",
    "                                      'Resource type(s)':[], \n",
    "                                      'Rights':[],\n",
    "                                      'Creator':[], \n",
    "                                      'Contributor':[], \n",
    "                                      'Description':[], \n",
    "                                      'Abstract':[],\n",
    "                                      'Original Bibliographic Citation':[], \n",
    "                                      'Related URL':[], \n",
    "                                      'Publisher':[],\n",
    "                                      'Date Created':[], \n",
    "                                      'Original Identifier':[], \n",
    "                                      'Language':[], \n",
    "                                      'Subject: MESH':[],\n",
    "                                      'Subject: LCSH':[], \n",
    "                                      'Subject: Geographic Name':[], \n",
    "                                      'Subject: Name':[],\n",
    "                                      'Location':[],\n",
    "                                      'Digital Origin':[], \n",
    "                                      'Id':'researchers-collections',                                           \n",
    "                                      'uri':[],\n",
    "                                      'members':[{'Id': 'e5e1683f-5075-4afd-9eba-2a36fc981414'}, ## Previous: e1683f-5075-4afd-9eba-2a36fc981414    \n",
    "                                                  {'Id': '7badb7c9-d4ec-4ca9-b58e-6e01f224fcf7'},\n",
    "                                                  {'Id': 'd0798568-47c3-453e-ae39-242d8a96b1dc'},\n",
    "                                                  {'Id': '913f8fa2-06c9-49e1-9cdf-0f88118b18da'},\n",
    "                                                  {'Id': '8s45q876k'},\n",
    "                                                  {'Id': '3ca02e5e-83be-4ea7-b51f-11aee3497e6c'},\n",
    "                                                  {'Id': 'afec3d3f-5ee6-468a-b8b4-80ab6d0402ac'},\n",
    "                                                  {'Id': 'ea926798-0e47-4441-b159-8af916499af3'},\n",
    "                                                  {'Id': '6b2bc47e-a3da-4222-8b8b-39e3b2832648'},\n",
    "                                                  {'Id': 'fj236212d'},\n",
    "                                                  {'Id': 'ed5f344a-8a48-4b50-9843-895634e5cd6a'},\n",
    "                                                  {'Id': 'kw52j804p'},\n",
    "                                                  {'Id': '96fc0e70-98e7-4e49-9784-8aa6942fc2a6'},\n",
    "                                                  {'Id': 'ae47e062-d7f8-49c0-8ffa-ce86fb2855ca'},\n",
    "                                                  {'Id': '91a4a3c2-e9f8-4540-85bb-5b69923106c0'},\n",
    "                                                  {'Id': '09e7110d-7677-4b82-985a-a7c26ac46b57'},\n",
    "                                                  {'Id': '55da1441-ddee-4f57-9c17-d371f78f2ed4'},\n",
    "                                                  {'Id': '9aa727f0-29d0-44af-ae9f-1018208cec89'},\n",
    "                                                  {'Id': 'd50c6f56-2600-4e67-ba4f-ee681eeae64c'},\n",
    "                                                  {'Id': '19673087-b6a5-4108-b285-9614aa8b6b95'},\n",
    "                                                  {'Id': 'rb68xb84x'},\n",
    "                                                  {'Id': '0d944080-d8ec-4386-abb0-c5ca34d2a3f5'},\n",
    "                                                  {'Id': 'a0deab15-7c16-4c52-86f8-80c96a2fb888'},\n",
    "                                                  {'Id': 'e0338411-7829-49ac-8fdc-cd17b7307474'},\n",
    "                                                  {'Id': '2dd287f0-9748-41f7-8fab-222db450d196'},\n",
    "                                                  {'Id': '5f1b1739-512f-4015-98bc-22f37f42af7b'},\n",
    "                                                  {'Id': '96fc0e70-98e7-4e49-9784-8aa6942fc2a6'},\n",
    "                                                  {'Id': '2d8b503f-203c-48ce-ac34-d0c976997761'},\n",
    "                                                  {'Id': 'aa31fe0c-41ec-46fd-82c0-405f168a5606'},\n",
    "                                                  {'Id': '1d4cede9-d8d6-4576-994d-91d36bd15b0b'},\n",
    "                                                  {'Id': '74d22173-8b26-4d34-b0a0-8b7b15bca6f8'}]\n",
    "                                     }])\n",
    "                                      \n",
    "                                           \n",
    "added_communities_df.head()                           \n",
    "## Checked: No problems  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea5c1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NOT NEEDED FOR RUN THROUGH DIGITALHUB, just for adding to \"desired\" organization for migrating to Prism\n",
    "\n",
    "## Concatenate the DigitalHub Community Dataframe to the added_communities_df\n",
    "\n",
    "digitalhub_community_df = pd.concat([digitalhub_community_df, added_communities_df], axis=0)\n",
    "digitalhub_community_df.reset_index(inplace=True, drop=True) \n",
    "# digitalhub_community_df.head(10)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b8f0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add Column to digitalhub_community_df to indicate that these results are a community\n",
    "\n",
    "digitalhub_community_df[\"Level Type\"] = \"Community\"\n",
    "digitalhub_community_df[\"Level Number\"] = \"1\"\n",
    "digitalhub_community_df['Level Number'] = digitalhub_community_df['Level Number'].apply(int)\n",
    "\n",
    "## Create a column from the index\n",
    "\n",
    "digitalhub_community_df['community_rowid'] = digitalhub_community_df.index\n",
    "\n",
    "## Create a new column called Community_ID\n",
    "\n",
    "digitalhub_community_df['Community_ID'] = digitalhub_community_df['Id']\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc86f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Inspect the \"members\" column and create a list of member IDs\n",
    "\n",
    "# row_member_list = []\n",
    "# column_member ={}\n",
    "# count_member = {}\n",
    "\n",
    "# for k, v in digitalhub_community_df[\"members\"].items():\n",
    "#     for value in v: \n",
    "#         member = value[\"Id\"]\n",
    "#         row_member_list.append(member)\n",
    "#     column_member[k] = row_member_list\n",
    "#     count_member[k] = len(row_member_list)\n",
    "#     row_member_list =[]\n",
    "#     row_member_count = []\n",
    "\n",
    "# ## Append the column member dictionary to the DigitalHub Community DF dataframe\n",
    "\n",
    "# digitalhub_community_df['Member_List'] = digitalhub_community_df.index.map(column_member)\n",
    "# digitalhub_community_df['Member_List_Count'] = digitalhub_community_df.index.map(count_member)\n",
    "# digitalhub_community_df.head()\n",
    "\n",
    "# ## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df198b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NOT NEEDED FOR RUN THROUGH DIGITALHUB, just for adding to \"desired\" organization for migrating to Prism\n",
    "\n",
    "###########################################################################\n",
    "##### Add private records to communities || Add sub_collections to communities#####\n",
    "###########################################################################\n",
    "\n",
    "\n",
    "######################################\n",
    "### Add new subcollections to GHSL###\n",
    "#####################################\n",
    "\n",
    "## Add subcollections to GHSL: \n",
    "# 8c1d851c-a5e6-4790-a867-fa889e66630e - med subject headings\n",
    "# 91294b2e-34e4-46ac-9086-be17c40d0d01 - operation saving lives\n",
    "# 8a281ff6-dd0e-4a02-8486-97c3bc7058c4 - pursuit of a grand cause\n",
    "# k0698748f - daniel hale\n",
    "# d526f63d-f10a-423d-bb81-bc32cc70b427 - notable women\n",
    "# ec202d45-992f-4f21-b3ea-d02703ca7621 - men behind\n",
    "\n",
    "add_to_series = [{'Multi-page?':[], \n",
    "                  'Title':'Operation Saving Lives: Northwestern as the 12th General Hospital During WWI',\n",
    "                  'Keyword':[], \n",
    "                  'Resource type(s)':[], \n",
    "                  'Rights':[],\n",
    "                  'Creator':[], \n",
    "                  'Contributor':[], \n",
    "                  'Description':[], \n",
    "                  'Abstract':[],\n",
    "                  'Original Bibliographic Citation':[], \n",
    "                  'Related URL':[], \n",
    "                  'Publisher':[],\n",
    "                  'Date Created':[], \n",
    "                  'Original Identifier':[], \n",
    "                  'Language':[], \n",
    "                  'Subject: MESH':[],\n",
    "                  'Subject: LCSH':[], \n",
    "                  'Subject: Geographic Name':[], \n",
    "                  'Subject: Name':[],\n",
    "                  'Location':[],\n",
    "                  'Digital Origin':[], \n",
    "                  'Id':'91294b2e-34e4-46ac-9086-be17c40d0d01',                                           \n",
    "                  'uri':[],\n",
    "                  'members':[{'Id':'ec5cbb80-61dd-47a4-87eb-c5bacd211e90'},\n",
    "                              {'Id':'5185bcc8-bc82-4e9b-aeca-a6aec040a8eb'},\n",
    "                              {'Id':'710ff4c3-8f1e-480d-baf9-a425ea936534'},\n",
    "                              {'Id':'c1cacdba-9705-4420-b58b-02e9975cc02b'},\n",
    "                              {'Id':'4f0d22bb-84f9-41aa-a834-a9fa1609d1ac'}]                                                 \n",
    "                 },{'Multi-page?':[], \n",
    "                  'Title':'Medical Subject Headings-Library of Congress Subject Headings Mapping Data',\n",
    "                  'Keyword':[], \n",
    "                  'Resource type(s)':[], \n",
    "                  'Rights':[],\n",
    "                  'Creator':[], \n",
    "                  'Contributor':[], \n",
    "                  'Description':[], \n",
    "                  'Abstract':[],\n",
    "                  'Original Bibliographic Citation':[], \n",
    "                  'Related URL':[], \n",
    "                  'Publisher':[],\n",
    "                  'Date Created':[], \n",
    "                  'Original Identifier':[], \n",
    "                  'Language':[], \n",
    "                  'Subject: MESH':[],\n",
    "                  'Subject: LCSH':[], \n",
    "                  'Subject: Geographic Name':[], \n",
    "                  'Subject: Name':[],\n",
    "                  'Location':[],\n",
    "                  'Digital Origin':[], \n",
    "                  'Id': '8c1d851c-a5e6-4790-a867-fa889e66630e',\n",
    "                  # previously: 'Id':'91294b2e-34e4-46ac-9086-be17c40d0d01s',                                           \n",
    "                  'uri':[],\n",
    "                  'members':[{'Id':'3e59c5b9-bbbf-4f49-946f-e08ef9b10d9f'},\n",
    "                              {'Id':'4b7f6a77-9cf4-4deb-b9aa-f3f49391bcc8'}] \n",
    "\n",
    "                 },{'Multi-page?':[], \n",
    "                  'Title':'In Pursuit of a Grand Cause',\n",
    "                  'Keyword':[], \n",
    "                  'Resource type(s)':[], \n",
    "                  'Rights':[],\n",
    "                  'Creator':[], \n",
    "                  'Contributor':[], \n",
    "                  'Description':[], \n",
    "                  'Abstract':[],\n",
    "                  'Original Bibliographic Citation':[], \n",
    "                  'Related URL':[], \n",
    "                  'Publisher':[],\n",
    "                  'Date Created':[], \n",
    "                  'Original Identifier':[], \n",
    "                  'Language':[], \n",
    "                  'Subject: MESH':[],\n",
    "                  'Subject: LCSH':[], \n",
    "                  'Subject: Geographic Name':[], \n",
    "                  'Subject: Name':[],\n",
    "                  'Location':[],\n",
    "                  'Digital Origin':[], \n",
    "                  'Id':'8a281ff6-dd0e-4a02-8486-97c3bc7058c4',                                           \n",
    "                  'uri':[],\n",
    "                  'members':[{'Id':'f9da4c66-fab8-4ecf-9862-8b016ed0a124'},\n",
    "                             {'Id':'f4a757f6-a617-496b-b040-df0b27ff8cf2'},\n",
    "                             {'Id':'20dcde30-f1f6-4386-9620-6fa5b1cb3467'},\n",
    "                             {'Id':'66708bc0-e8d0-4b44-8057-c0b8dbaa0566'},\n",
    "                             {'Id':'2320576d-a6c8-422f-a074-b34180d15442'},\n",
    "                             {'Id':'33e474af-6e46-4bac-9e42-96dbf4bcb51e'}]\n",
    "                },{'Multi-page?':[], \n",
    "                  'Title':'Daniel Hale Williams, Surgeon, Educator & Medical Advocate',\n",
    "                  'Keyword':[], \n",
    "                  'Resource type(s)':[], \n",
    "                  'Rights':[],\n",
    "                  'Creator':[], \n",
    "                  'Contributor':[], \n",
    "                  'Description':[], \n",
    "                  'Abstract':[],\n",
    "                  'Original Bibliographic Citation':[], \n",
    "                  'Related URL':[], \n",
    "                  'Publisher':[],\n",
    "                  'Date Created':[], \n",
    "                  'Original Identifier':[], \n",
    "                  'Language':[], \n",
    "                  'Subject: MESH':[],\n",
    "                  'Subject: LCSH':[], \n",
    "                  'Subject: Geographic Name':[], \n",
    "                  'Subject: Name':[],\n",
    "                  'Location':[],\n",
    "                  'Digital Origin':[], \n",
    "                  'Id':'k0698748f',                                           \n",
    "                  'uri':[],\n",
    "                  'members':[],\n",
    "                   'DOI': ['doi: 10.18131/G3HS3J']\n",
    "                },{'Multi-page?':[], \n",
    "                  'Title':'Notable Women of the Womans Medical School',\n",
    "                  'Keyword':[], \n",
    "                  'Resource type(s)':[], \n",
    "                  'Rights':[],\n",
    "                  'Creator':[], \n",
    "                  'Contributor':[], \n",
    "                  'Description':[], \n",
    "                  'Abstract':[],\n",
    "                  'Original Bibliographic Citation':[], \n",
    "                  'Related URL':[], \n",
    "                  'Publisher':[],\n",
    "                  'Date Created':[], \n",
    "                  'Original Identifier':[], \n",
    "                  'Language':[], \n",
    "                  'Subject: MESH':[],\n",
    "                  'Subject: LCSH':[], \n",
    "                  'Subject: Geographic Name':[], \n",
    "                  'Subject: Name':[],\n",
    "                  'Location':[],\n",
    "                  'Digital Origin':[], \n",
    "                  'Id':'d526f63d-f10a-423d-bb81-bc32cc70b427', \n",
    "                  'uri':[],\n",
    "                  'members':[],\n",
    "                  'DOI' : ['doi: 10.18131/G3BF1S']\n",
    "                },{'Multi-page?':[], \n",
    "                  'Title':'Men Behind the Women at the Womans Medical School at Northwestern University Medical School',\n",
    "                  'Keyword':[], \n",
    "                  'Resource type(s)':[], \n",
    "                  'Rights':[],\n",
    "                  'Creator':[], \n",
    "                  'Contributor':[], \n",
    "                  'Description':[], \n",
    "                  'Abstract':[],\n",
    "                  'Original Bibliographic Citation':[], \n",
    "                  'Related URL':[], \n",
    "                  'Publisher':[],\n",
    "                  'Date Created':[], \n",
    "                  'Original Identifier':[], \n",
    "                  'Language':[], \n",
    "                  'Subject: MESH':[],\n",
    "                  'Subject: LCSH':[], \n",
    "                  'Subject: Geographic Name':[], \n",
    "                  'Subject: Name':[],\n",
    "                  'Location':[],\n",
    "                  'Digital Origin':[], \n",
    "                  'Id':'ec202d45-992f-4f21-b3ea-d02703ca7621',                                           \n",
    "                  'uri':[],\n",
    "                  'members':[],\n",
    "                  'DOI':['doi:10.18131/g3-px5e-7r70']\n",
    "                  }] \n",
    "\n",
    "\n",
    "\n",
    "## Identify the series that this list needs to be added to\n",
    "current_series = digitalhub_community_df.loc[digitalhub_community_df['Id'] == 'fj2362114','members']\n",
    "# print(current_series.item()[0])\n",
    "\n",
    "\n",
    "current_list=[]\n",
    "current_list = current_series.tolist()\n",
    "\n",
    "## Add items from add_to_series list to current_series\n",
    "ghsl_result = []\n",
    "ghsl_result = current_series.item() + [x for x in add_to_series if x not in current_series.items()]\n",
    "print(len(ghsl_result))\n",
    "# print(ghsl_result)\n",
    "\n",
    "## Add GHSL result back to member\n",
    "digitalhub_community_df['members'] = digitalhub_community_df['members'].astype('object')\n",
    "digitalhub_community_df.at[4,'members'] = ghsl_result\n",
    "\n",
    "#################################################################\n",
    "### Add new subcollections to Biostatistics Collaboration Core###\n",
    "################################################################\n",
    "\n",
    "## Add subcollections to BCC: \n",
    "## 2735afc8-70e9-43db-a85f-3ccac4d18e61 - Statistically Speaking Lecture Series 2021-2022\n",
    "## Give new name: 2021-2022\n",
    "## BCC is: 2cc92425-b656-47ea-a3b4-825405ee6088\n",
    "\n",
    "add_to_series_2 = [{'Multi-page?':[], \n",
    "                  'Title':'2021-2022',\n",
    "                  'Keyword':[], \n",
    "                  'Resource type(s)':[], \n",
    "                  'Rights':[],\n",
    "                  'Creator':[], \n",
    "                  'Contributor':[], \n",
    "                  'Description':[], \n",
    "                  'Abstract':[],\n",
    "                  'Original Bibliographic Citation':[], \n",
    "                  'Related URL':[], \n",
    "                  'Publisher':[],\n",
    "                  'Date Created':[], \n",
    "                  'Original Identifier':[], \n",
    "                  'Language':[], \n",
    "                  'Subject: MESH':[],\n",
    "                  'Subject: LCSH':[], \n",
    "                  'Subject: Geographic Name':[], \n",
    "                  'Subject: Name':[],\n",
    "                  'Location':[],\n",
    "                  'Digital Origin':[], \n",
    "                  'Id':'2735afc8-70e9-43db-a85f-3ccac4d18e61',                                           \n",
    "                  'uri':[],\n",
    "                  'members':[{'Id':'2788f1e6-90b5-4aca-aef8-4a600dbc786b'},\n",
    "                              {'Id':'baad30fa-7f5d-47e3-b810-9252794d76f1'},\n",
    "                              {'Id':'c8255e80-6d6c-4780-83e5-dd8b81ece87f'},\n",
    "                              {'Id':'a21f49f2-2236-49d1-8a66-6193a7837ef5'}] \n",
    "                \n",
    "                 }]\n",
    "\n",
    "\n",
    "## Identify the series that this list needs to be added to\n",
    "## \"DOI\":[\"doi:10.18131/g3-g89w-rg50\"]\n",
    "current_series_2 = digitalhub_community_df.loc[digitalhub_community_df['Id'] == '2cc92425-b656-47ea-a3b4-825405ee6088','members']\n",
    "# print(current_series_2.item()[0])\n",
    "\n",
    "## Likely don't need to make it a list...\n",
    "current_list_2=[]\n",
    "current_list_2 = current_series_2.tolist()\n",
    "\n",
    "## Add items from add_to_series list to current_series\n",
    "bcc_result = []\n",
    "bcc_result = current_series_2.item() + [x for x in add_to_series_2 if x not in current_series_2.items()]\n",
    "print(len(bcc_result))\n",
    "# print(bcc_result)\n",
    "\n",
    "## Add BCC result back to member\n",
    "\n",
    "digitalhub_community_df['members'] = digitalhub_community_df['members'].astype('object')\n",
    "digitalhub_community_df.at[0,'members'] = bcc_result\n",
    "                              \n",
    "\n",
    "######################################\n",
    "### Add new subcollections to CBITs###\n",
    "#####################################\n",
    "\n",
    "# add_to_series_3 = {\"Multi-page?\":false,\n",
    "#                    \"Title\":\"CBITs IRB Materials\",\n",
    "#                    \"Keyword\":[\"Digital Mental Health\",\"IRB\"],\n",
    "#                    \"Resource type(s)\":[],\n",
    "#                    \"Rights\":[],\n",
    "#                    \"Creator\":[],\n",
    "#                    \"Contributor\":[],\n",
    "#                    \"Description\":\"This collection will serve as a repository of submitted and approved IRB materials for research projects within the Center for Behavioral Intervention Technologies (CBITs). \",\n",
    "#                    \"Abstract\":[],\n",
    "#                    \"Original Bibliographic Citation\":[],\n",
    "#                    \"Related URL\":[\"https://digitalhub.northwestern.edu/collections/2e61510b-939f-4637-9fd9-c31f1013c661\",\" http://cbits.northwestern.edu/\"],\n",
    "#                    \"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\n",
    "#                    \"Date Created\":[\"12/2/2020\"],\n",
    "#                    \"Original Identifier\":[],\n",
    "#                    \"Language\":[],\n",
    "#                    \"Subject: MESH\":[],\n",
    "#                    \"Subject: LCSH\":[],\n",
    "#                    \"Subject: Geographic Name\":[],\n",
    "#                    \"Subject: Name\":[],\n",
    "#                    \"Location\":[],\n",
    "#                    \"Digital Origin\":[],\n",
    "#                    \"Id\":\"27114af7-6444-4f3c-8de1-3e9c5dc73e95\",\n",
    "#                    \"uri\":\"https://digitalhub.northwestern.edu/collections/27114af7-6444-4f3c-8de1-3e9c5dc73e95\",\n",
    "#                    \"members\":[{\"Title\":[\"\\\"ACTS Process Evaluation Project\\\" Human Research Determination Form\"],\"Resource type(s)\":[\"Study Design\"],\"Keyword\":[\"Technology Enabled Services\",\"Digital Mental Health\",\"Human Research Determination Form\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":null,\"Original Identifier\":null,\"Language\":null,\"Subject: MESH\":null,\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-g89w-rg50\"],\"ARK\":null,\"Id\":\"e92db21d-e121-4b32-b6c8-353727e2675f\",\"File Size\":54220,\"File Format\":[\"msword (Microsoft Word Document, OpenDocument Text, Office Open XML Document)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/e92db21d-e121-4b32-b6c8-353727e2675f\",\"download\":\"https://digitalhub.northwestern.edu/downloads/e92db21d-e121-4b32-b6c8-353727e2675f\"},\n",
    "#                               {\"Title\":[\"\\\"Examining the switch to remote-delivered mental health services among college counseling center clinicians\\\" Consent.pdf\"],\"Resource type(s)\":[\"Study Design\"],\"Keyword\":[\"Digital Mental Health\",\"Consent\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2020\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Student Health Services\",\"Mental Health Services\",\"Telemedicine\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-3qga-6c80\"],\"ARK\":null,\"Id\":\"9ae9f025-f11d-4d7b-b721-e6f957ce78f4\",\"File Size\":100919,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/9ae9f025-f11d-4d7b-b721-e6f957ce78f4\",\"download\":\"https://digitalhub.northwestern.edu/downloads/9ae9f025-f11d-4d7b-b721-e6f957ce78f4\"},\n",
    "#                               {\"Title\":[\"\\\"Examining the switch to remote-delivered mental health services among college counseling center clinicians\\\" Protocol.pdf\"],\"Resource type(s)\":[\"Study Design\"],\"Keyword\":[\"Digital Mental Health\",\"IRB Protocol\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2020-06-26\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Student Health Services\",\"Mental Health Services\",\"Counseling--methods\",\"Telemedicine\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-zbz3-6989\"],\"ARK\":null,\"Id\":\"aaf1a825-6927-4df7-be64-4b0cb0ec6157\",\"File Size\":102338,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/aaf1a825-6927-4df7-be64-4b0cb0ec6157\",\"download\":\"https://digitalhub.northwestern.edu/downloads/aaf1a825-6927-4df7-be64-4b0cb0ec6157\"},{\"Title\":[\"\\\"Examining the switch to remote-delivered mental health services among college counseling center clinicians\\\" Recruitment Email.pdf\"],\"Resource type(s)\":[\"Study Design\"],\"Keyword\":[\"Digital Mental Health\",\"Recruitment\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2020\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Mental Health Services\",\"Telemedicine\",\"Student Health Services\",\"Counseling--methods\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-90n7-rn16\"],\"ARK\":null,\"Id\":\"b7681fcb-d62b-471e-a4c1-e1846962a008\",\"File Size\":79594,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/b7681fcb-d62b-471e-a4c1-e1846962a008\",\"download\":\"https://digitalhub.northwestern.edu/downloads/b7681fcb-d62b-471e-a4c1-e1846962a008\"},{\"Title\":[\"\\\"Examining the switch to remote-delivered mental health services among college counseling center clinicians\\\" Survey.pdf\"],\"Resource type(s)\":[\"Forms\"],\"Keyword\":[\"Digital Mental Health\",\"Survey\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2020\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Mental Health Services\",\"Student Health Services\",\"Telemedicine\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-p4mj-c759\"],\"ARK\":null,\"Id\":\"599b5800-878b-43ee-a322-a2c448139786\",\"File Size\":103118,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/599b5800-878b-43ee-a322-a2c448139786\",\"download\":\"https://digitalhub.northwestern.edu/downloads/599b5800-878b-43ee-a322-a2c448139786\"},\n",
    "#                               {\"Title\":[\"\\\"Investigation of Care Managed Patient Experience and Interest in Technology Enabled Mental Health Care Delivery\\\" Consent.pdf\"],\"Resource type(s)\":[\"Study Design\"],\"Keyword\":[\"Digital Mental Health\",\"Technology Enabled Services\",\"Consent\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":null,\"Original Identifier\":null,\"Language\":null,\"Subject: MESH\":null,\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-qk7e-wv85\"],\"ARK\":null,\"Id\":\"39a0c5c0-55c8-4c65-b62a-10234b8fbf5a\",\"File Size\":77731,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/39a0c5c0-55c8-4c65-b62a-10234b8fbf5a\",\"download\":\"https://digitalhub.northwestern.edu/downloads/39a0c5c0-55c8-4c65-b62a-10234b8fbf5a\"},{\"Title\":[\"\\\"Investigation of Care Managed Patient Experience and Interest in Technology Enabled Mental Health Care Delivery\\\" Email Script.pdf\"],\"Resource type(s)\":[\"Study Design\"],\"Keyword\":[\"Digital Mental Health\",\"Technology Enabled Services\",\"Recruitment\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2020\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Mental Health Services\",\"Telemedicine\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-snd8-kj17\"],\"ARK\":null,\"Id\":\"47e976ca-79db-441e-8e20-d9848a9b6b6e\",\"File Size\":37445,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/47e976ca-79db-441e-8e20-d9848a9b6b6e\",\"download\":\"https://digitalhub.northwestern.edu/downloads/47e976ca-79db-441e-8e20-d9848a9b6b6e\"},{\"Title\":[\"\\\"Investigation of Care Managed Patient Experience and Interest in Technology Enabled Mental Health Care Delivery\\\" Recruitment Script.pdf\"],\"Resource type(s)\":[\"Study Design\"],\"Keyword\":[\"Digital Mental Health\",\"Technology Enabled Services\",\"Recruitment\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2020\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Mental Health Services\",\"Telemedicine\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-xcpm-sm06\"],\"ARK\":null,\"Id\":\"1164b65b-7dac-48b4-9c31-2936a4da9b91\",\"File Size\":17740,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/1164b65b-7dac-48b4-9c31-2936a4da9b91\",\"download\":\"https://digitalhub.northwestern.edu/downloads/1164b65b-7dac-48b4-9c31-2936a4da9b91\"},{\"Title\":[\"\\\"Investigation of Care Managed Patient Experience and Interest in Technology Enabled Mental Health Care Delivery\\\" Screening Measure.pdf\"],\"Resource type(s)\":[\"Forms\"],\"Keyword\":[\"Digital Mental Health\",\"Technology Enabled Services\",\"Screening\"],\"Rights\":null,\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2020\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Mental Health Services\",\"Telemedicine\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-s639-q225\"],\"ARK\":null,\"Id\":\"a9e3ab90-1a67-438b-8a37-8208c909d851\",\"File Size\":144509,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/a9e3ab90-1a67-438b-8a37-8208c909d851\",\"download\":\"https://digitalhub.northwestern.edu/downloads/a9e3ab90-1a67-438b-8a37-8208c909d851\"},{\"Title\":[\"\\\"Investigation of Care Managed Patient Experience and Interest in Technology Enabled Mental Health Care Delivery\\\" Study Protocol.pdf\"],\"Resource type(s)\":[\"Study Design\"],\"Keyword\":[\"Digital Mental Health\",\"IRB Protocol\",\"Technology Enabled Services\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2020\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Mental Health Services\",\"Telemedicine\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-prvq-mf27\"],\"ARK\":null,\"Id\":\"6cc12e96-e189-40c7-b473-7592e85b33c0\",\"File Size\":129937,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/6cc12e96-e189-40c7-b473-7592e85b33c0\",\"download\":\"https://digitalhub.northwestern.edu/downloads/6cc12e96-e189-40c7-b473-7592e85b33c0\"},{\"Title\":[\"\\\"Self-Management and Care Collaboration for Perinatal Depression\\\" Client Consent\"],\"Resource type(s)\":[\"Forms\"],\"Keyword\":[\"Perinatal Depression\",\"Perinatal\",\"Depression\",\"Technology Enabled Services\",\"Digital Mental Health\",\"Design\",\"RP2\",\"Consent\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2019\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Depression, Postpartum\",\"Depressive Disorder--therapy\",\"Self Care--methods\",\"Patient Participation\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-r5h0-ge74\"],\"ARK\":null,\"Id\":\"37d6264d-9e10-4967-9fe6-7dff6f0b6690\",\"File Size\":113390,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/37d6264d-9e10-4967-9fe6-7dff6f0b6690\",\"download\":\"https://digitalhub.northwestern.edu/downloads/37d6264d-9e10-4967-9fe6-7dff6f0b6690\"},{\"Title\":[\"\\\"Self-Management and Care Collaboration for Perinatal Depression\\\" Client Interview Protocol\"],\"Resource type(s)\":[\"Other\"],\"Keyword\":[\"Interview\",\"Perinatal Depression\",\"Perinatal\",\"Depression\",\"Technology Enabled Services\",\"Digital Mental Health\",\"Design\",\"RP2\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2019\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Depression, Postpartum\",\"Depressive Disorder\",\"Patient Participation\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-4hqk-xb13\"],\"ARK\":null,\"Id\":\"1f5e9faf-f18b-46f6-8964-156650d33c21\",\"File Size\":15831,\"File Format\":[\"msword (Microsoft Word Document, OpenDocument Text, Office Open XML Document)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/1f5e9faf-f18b-46f6-8964-156650d33c21\",\"download\":\"https://digitalhub.northwestern.edu/downloads/1f5e9faf-f18b-46f6-8964-156650d33c21\"},{\"Title\":[\"\\\"Self-Management and Care Collaboration for Perinatal Depression\\\" Design Study Protocol\"],\"Resource type(s)\":[\"Study Design\"],\"Keyword\":[\"IRB Protocol\",\"Perinatal\",\"Depression\",\"Technology Enabled Services\",\"Digital Mental Health\",\"Design\",\"Perinatal Depression\",\"RP2\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2019\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Depression, Postpartum\",\"Depressive Disorder--therapy\",\"Self Care--methods\",\"Patient Participation\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-km8y-a478\"],\"ARK\":null,\"Id\":\"02e5eb3b-46ac-41fc-ae58-017803460cb8\",\"File Size\":257093,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/02e5eb3b-46ac-41fc-ae58-017803460cb8\",\"download\":\"https://digitalhub.northwestern.edu/downloads/02e5eb3b-46ac-41fc-ae58-017803460cb8\"},{\"Title\":[\"\\\"Self-Management and Care Collaboration for Perinatal Depression\\\" Recruitment Script\"],\"Resource type(s)\":[\"Other\"],\"Keyword\":[\"Recruitment\",\"Perinatal Depression\",\"Perinatal\",\"Depression\",\"Technology Enabled Services\",\"Digital Mental Health\",\"RP2\",\"Design\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2019\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Depression, Postpartum\",\"Patient Participation\",\"Depressive Disorder\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-rbv4-3275\"],\"ARK\":null,\"Id\":\"8c78bf3e-8afd-4782-a71c-ccf7c0917ef3\",\"File Size\":14893,\"File Format\":[\"msword (Microsoft Word Document, OpenDocument Text, Office Open XML Document)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/8c78bf3e-8afd-4782-a71c-ccf7c0917ef3\",\"download\":\"https://digitalhub.northwestern.edu/downloads/8c78bf3e-8afd-4782-a71c-ccf7c0917ef3\"},{\"Title\":[\"\\\"Self-Management and Care Collaboration for Perinatal Depression\\\" Stakeholder Consent\"],\"Resource type(s)\":[\"Forms\"],\"Keyword\":[\"Perinatal Depression\",\"Perinatal\",\"Depression\",\"Technology Enabled Services\",\"Digital Mental Health\",\"Design\",\"RP2\",\"Consent\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2019\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Depression, Postpartum\",\"Depressive Disorder--therapy\",\"Patient Participation\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-dgcx-vn70\"],\"ARK\":null,\"Id\":\"b5fc4ef9-c3d2-4ba5-9902-280294f68447\",\"File Size\":111287,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/b5fc4ef9-c3d2-4ba5-9902-280294f68447\",\"download\":\"https://digitalhub.northwestern.edu/downloads/b5fc4ef9-c3d2-4ba5-9902-280294f68447\"},{\"Title\":[\"\\\"Self-Management and Care Collaboration for Perinatal Depression\\\" Stakeholder Interview Protocol\"],\"Resource type(s)\":[\"Other\"],\"Keyword\":[\"Interview\",\"Perinatal Depression\",\"Perinatal\",\"Depression\",\"Technology Enabled Services\",\"Digital Mental Health\",\"Design\",\"RP2\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2019\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Depression, Postpartum\",\"Depressive Disorder--therapy\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-8m3q-qj71\"],\"ARK\":null,\"Id\":\"1951c9b0-f350-4198-a15d-84dff985485b\",\"File Size\":15246,\"File Format\":[\"msword (Microsoft Word Document, OpenDocument Text, Office Open XML Document)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/1951c9b0-f350-4198-a15d-84dff985485b\",\"download\":\"https://digitalhub.northwestern.edu/downloads/1951c9b0-f350-4198-a15d-84dff985485b\"},{\"Title\":[\"\\\"Usability testing of an oncology patient-facing symptom management website\\\" Human Subjects Determinaton Form.pdf\"],\"Resource type(s)\":[\"Study Design\"],\"Keyword\":[\"Oncology\",\"Human Research Determination Form\",\"Design\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2019-09-09\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Neoplasms\",\"Online Systems\"],\"Subject: LCSH\":[\"Web site development\"],\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-mve9-eg63\"],\"ARK\":null,\"Id\":\"19006705-18d6-4e58-ae93-4a310a808ee1\",\"File Size\":99361,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/19006705-18d6-4e58-ae93-4a310a808ee1\",\"download\":\"https://digitalhub.northwestern.edu/downloads/19006705-18d6-4e58-ae93-4a310a808ee1\"},{\"Title\":[\"\\\"Usability testing of an oncology patient-facing symptom management website\\\" Usability Session Guide.pdf\"],\"Resource type(s)\":[\"Study Design\"],\"Keyword\":[\"Usability Session\",\"Oncology\",\"Design\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2020\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Neoplasms\",\"Online Systems\"],\"Subject: LCSH\":[\"Web site development\"],\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-fs0d-bc32\"],\"ARK\":null,\"Id\":\"6f98547f-6fbf-4a88-afaa-7f06d58e2d3b\",\"File Size\":114549,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/6f98547f-6fbf-4a88-afaa-7f06d58e2d3b\",\"download\":\"https://digitalhub.northwestern.edu/downloads/6f98547f-6fbf-4a88-afaa-7f06d58e2d3b\"},{\"Title\":[\"Design Opportunities for Mental Health Technologies for Youth. Adolescent Assent\"],\"Resource type(s)\":[\"Study Design\"],\"Keyword\":[\"Digital Mental Health\",\"Children\",\"Consent\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2020-06\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Mental Health\",\"Telemedicine\",\"Digital Technology\",\"Adolescent\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":[\"Northwestern University, Jacobs Foundation, and the Delaney Foundation\"],\"DOI\":[\"doi:10.18131/g3-vqbv-9r77\"],\"ARK\":null,\"Id\":\"5d6c9b9c-e976-4447-b681-d4b5f0310a8c\",\"File Size\":112954,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/5d6c9b9c-e976-4447-b681-d4b5f0310a8c\",\"download\":\"https://digitalhub.northwestern.edu/downloads/5d6c9b9c-e976-4447-b681-d4b5f0310a8c\"},{\"Title\":[\"Design Opportunities for Mental Health Technologies for Youth. Parent Consent\"],\"Resource type(s)\":[\"Study Design\"],\"Keyword\":[\"Digital Mental Health\",\"Children\",\"Consent\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2020-06\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Mental Health\",\"Telemedicine\",\"Digital Technology\",\"Adolescent\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":[\"This research is supported by the Jacobs Foundation, Delaney Foundation, and Northwestern University.\"],\"DOI\":[\"doi:10.18131/g3-fact-kz56\"],\"ARK\":null,\"Id\":\"c9ff3527-5051-4841-837b-831583d24671\",\"File Size\":120446,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/c9ff3527-5051-4841-837b-831583d24671\",\"download\":\"https://digitalhub.northwestern.edu/downloads/c9ff3527-5051-4841-837b-831583d24671\"},{\"Title\":[\"Design Opportunities for Mental Health Technologies for Youth. Protocol\"],\"Resource type(s)\":[\"Study Design\"],\"Keyword\":[\"Digital Mental Health\",\"Children\",\"IRB Protocol\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2020-06-08\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Mental Health\",\"Telemedicine\",\"Adolescent\",\"Digital Technology\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-kd36-dy61\"],\"ARK\":null,\"Id\":\"1fa62981-70e7-4633-968c-8a1cd447292d\",\"File Size\":179836,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/1fa62981-70e7-4633-968c-8a1cd447292d\",\"download\":\"https://digitalhub.northwestern.edu/downloads/1fa62981-70e7-4633-968c-8a1cd447292d\"},{\"Title\":[\"Design Opportunities for Mental Health Technologies for Youth. Staff Interview Consent\"],\"Resource type(s)\":[\"Study Design\"],\"Keyword\":[\"Digital Mental Health\",\"Children\",\"Consent\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2020\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Mental Health\",\"Telemedicine\",\"Digital Technology\",\"Adolescent\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":[\"Northwestern University, Jacobs Foundation, and Delaney Foundation\"],\"DOI\":[\"doi:10.18131/g3-t6v7-z889\"],\"ARK\":null,\"Id\":\"d83918e6-d356-40b4-b4fa-4ccdf19f2dc3\",\"File Size\":122202,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/d83918e6-d356-40b4-b4fa-4ccdf19f2dc3\",\"download\":\"https://digitalhub.northwestern.edu/downloads/d83918e6-d356-40b4-b4fa-4ccdf19f2dc3\"},{\"Title\":[\"Design Opportunities for Mental Health Technologies for Youth. Staff Workshop Consent\"],\"Resource type(s)\":[\"Study Design\"],\"Keyword\":[\"Digital Mental Health\",\"Children\",\"Consent\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2020\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Mental Health\",\"Telemedicine \",\"Digital Technology\",\"Adolescent \"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":[\"Northwestern University, Jacobs Foundation, Delaney Foundation\"],\"DOI\":[\"doi:10.18131/g3-df79-mm47\"],\"ARK\":null,\"Id\":\"9509fce9-5147-4639-ad6a-ed5b2f3244d4\",\"File Size\":124596,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/9509fce9-5147-4639-ad6a-ed5b2f3244d4\",\"download\":\"https://digitalhub.northwestern.edu/downloads/9509fce9-5147-4639-ad6a-ed5b2f3244d4\"},{\"Title\":[\"Examining Millennial and Gen Z Preferences for Non-Traditional Mental Healthcare. Online Consent (13-17 years old)\"],\"Resource type(s)\":[\"Forms\"],\"Keyword\":[\"Digital Mental Health\",\"Consent\",\"Children\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2019\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Mental Health\",\"Health Surveys\",\"Adolescent\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-j90p-8k20\"],\"ARK\":null,\"Id\":\"c025062b-415a-4d18-b601-72feae58b472\",\"File Size\":118967,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/c025062b-415a-4d18-b601-72feae58b472\",\"download\":\"https://digitalhub.northwestern.edu/downloads/c025062b-415a-4d18-b601-72feae58b472\"},{\"Title\":[\"Examining Millennial and Gen Z Preferences for Non-Traditional Mental Healthcare. Online Consent (18 years or older)\"],\"Resource type(s)\":[\"Forms\"],\"Keyword\":[\"Digital Mental Health\",\"Consent\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2019\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Mental Health\",\"Health Surveys\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-8nfd-9s55\"],\"ARK\":null,\"Id\":\"a001b48d-63ef-42df-a7b0-3066ab70ac02\",\"File Size\":134120,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/a001b48d-63ef-42df-a7b0-3066ab70ac02\",\"download\":\"https://digitalhub.northwestern.edu/downloads/a001b48d-63ef-42df-a7b0-3066ab70ac02\"},{\"Title\":[\"Examining Millennial and Gen Z Preferences for Non-Traditional Mental Healthcare. Print Ad 1\"],\"Resource type(s)\":[\"Advertisements\"],\"Keyword\":[\"Digital Mental Health\",\"Recruitment\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2019\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Mental Health \",\"Health Surveys\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-3rfb-7q08\"],\"ARK\":null,\"Id\":\"3ac2ec9f-f558-4fa4-beae-12aa2c29e9a9\",\"File Size\":111087,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/3ac2ec9f-f558-4fa4-beae-12aa2c29e9a9\",\"download\":\"https://digitalhub.northwestern.edu/downloads/3ac2ec9f-f558-4fa4-beae-12aa2c29e9a9\"},{\"Title\":[\"Examining Millennial and Gen Z Preferences for Non-Traditional Mental Healthcare. Print Ad 2\"],\"Resource type(s)\":[\"Advertisements\"],\"Keyword\":[\"Digital Mental Health\",\"Recruitment\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2019\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Mental Health\",\"Health Surveys\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-mcc1-ha87\"],\"ARK\":null,\"Id\":\"4408aa75-6aad-4b89-b7df-b1e4895a1a0c\",\"File Size\":84618,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/4408aa75-6aad-4b89-b7df-b1e4895a1a0c\",\"download\":\"https://digitalhub.northwestern.edu/downloads/4408aa75-6aad-4b89-b7df-b1e4895a1a0c\"},{\"Title\":[\"Examining Millennial and Gen Z Preferences for Non-Traditional Mental Healthcare. Study Protocol\"],\"Resource type(s)\":[\"Study Design\"],\"Keyword\":[\"Digital Mental Health\",\"IRB Protocol\",\"Children\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2019\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Mental Health\",\"Health Surveys\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-97k2-gs87\"],\"ARK\":null,\"Id\":\"1c28693f-8920-4af9-9367-f94079ce3d48\",\"File Size\":164582,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/1c28693f-8920-4af9-9367-f94079ce3d48\",\"download\":\"https://digitalhub.northwestern.edu/downloads/1c28693f-8920-4af9-9367-f94079ce3d48\"},{\"Title\":[\"Examining Millennial and Gen Z Preferences for Non-Traditional Mental Healthcare. Survey\"],\"Resource type(s)\":[\"Forms\"],\"Keyword\":[\"Digital Mental Health\",\"Survey\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2019\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Mental Health\",\"Health Surveys\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-sf41-b528\"],\"ARK\":null,\"Id\":\"c9f5faae-2930-47a9-86ea-96c3f8c55656\",\"File Size\":84023,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/c9f5faae-2930-47a9-86ea-96c3f8c55656\",\"download\":\"https://digitalhub.northwestern.edu/downloads/c9f5faae-2930-47a9-86ea-96c3f8c55656\"},{\"Title\":[\"Implementing mobile apps for depression and anxiety in a community services agency. Interview Consent\"],\"Resource type(s)\":[\"Forms\"],\"Keyword\":[\"Digital Mental Health\",\"Depression\",\"Consent\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":null,\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Depression\",\"Anxiety\",\"Mobile Applications\",\"Mental Health Services\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-2m9d-7b44\"],\"ARK\":null,\"Id\":\"62211181-1379-4979-95bc-7b9e16acd8a9\",\"File Size\":44396,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/62211181-1379-4979-95bc-7b9e16acd8a9\",\"download\":\"https://digitalhub.northwestern.edu/downloads/62211181-1379-4979-95bc-7b9e16acd8a9\"},{\"Title\":[\"Implementing mobile apps for depression and anxiety in a community services agency. Protocol\"],\"Resource type(s)\":[\"Study Design\"],\"Keyword\":[\"Digital Mental Health\",\"Depression\",\"IRB Protocol\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2017\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Depression\",\"Anxiety\",\"Mobile Applications\",\"Community Health Services\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-grf2-rr06\"],\"ARK\":null,\"Id\":\"6ed9c44c-db1f-42d7-95ab-0560ca6bb382\",\"File Size\":60575,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/6ed9c44c-db1f-42d7-95ab-0560ca6bb382\",\"download\":\"https://digitalhub.northwestern.edu/downloads/6ed9c44c-db1f-42d7-95ab-0560ca6bb382\"},{\"Title\":[\"Implementing mobile apps for depression and anxiety in a community services agency. Recruitment Script\"],\"Resource type(s)\":[\"Study Design\"],\"Keyword\":[\"Digital Mental Health\",\"Depression\",\"Recruitment\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2018\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Depression\",\"Anxiety\",\"Mobile Applications\",\"Community Health Services\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-kzpq-qb16\"],\"ARK\":null,\"Id\":\"00441c78-a2cc-46d4-88db-7973142ef9ed\",\"File Size\":16541,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/00441c78-a2cc-46d4-88db-7973142ef9ed\",\"download\":\"https://digitalhub.northwestern.edu/downloads/00441c78-a2cc-46d4-88db-7973142ef9ed\"},{\"Title\":[\"Implementing mobile apps for depression and anxiety in a community services agency. Survey\"],\"Resource type(s)\":[\"Forms\"],\"Keyword\":[\"Digital Mental Health\",\"Depression\",\"Survey\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2018\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Depression\",\"Anxiety\",\"Mobile Applications\",\"Community Health Services\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-gktk-qp75\"],\"ARK\":null,\"Id\":\"0a0578fa-8818-4efe-857c-95dd9d8de58a\",\"File Size\":181860,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/0a0578fa-8818-4efe-857c-95dd9d8de58a\",\"download\":\"https://digitalhub.northwestern.edu/downloads/0a0578fa-8818-4efe-857c-95dd9d8de58a\"},{\"Title\":[\"Implementing mobile apps for depression and anxiety in a community services agency. Survey Consent\"],\"Resource type(s)\":[\"Forms\"],\"Keyword\":[\"Digital Mental Health\",\"Depression\",\"Consent\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":null,\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Depression\",\"Anxiety\",\"Mobile Applications\",\"Community Health Services\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-q57n-bk83\"],\"ARK\":null,\"Id\":\"a9b2c9ee-0950-44b8-bd93-5571c9fbc581\",\"File Size\":51954,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/a9b2c9ee-0950-44b8-bd93-5571c9fbc581\",\"download\":\"https://digitalhub.northwestern.edu/downloads/a9b2c9ee-0950-44b8-bd93-5571c9fbc581\"},{\"Title\":[\"IntelliCare Study. Consent\"],\"Resource type(s)\":[\"Forms\"],\"Keyword\":[\"Digital Mental Health\",\"Consent\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2018\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Depression\",\"Anxiety\",\"Mobile Applications\",\"Community Health Services\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-45by-0b98\"],\"ARK\":null,\"Id\":\"06f74810-a80b-43e9-b5b2-0c89e70eb184\",\"File Size\":287256,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/06f74810-a80b-43e9-b5b2-0c89e70eb184\",\"download\":\"https://digitalhub.northwestern.edu/downloads/06f74810-a80b-43e9-b5b2-0c89e70eb184\"},{\"Title\":[\"Technology-Enabled Prevention Services for At-Risk Youth. Design Session Adult Consent\"],\"Resource type(s)\":[\"Forms\"],\"Keyword\":[\"Digital Mental Health\",\"Children\",\"Technology Enabled Services\",\"Design\",\"Consent\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2020\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Anxiety Disorders--prevention \\u0026 control\",\"Digital Technology\",\"Adolescent\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":[\"This research is supported by Northwestern University and the National Institute of Mental Health. \"],\"DOI\":[\"doi:10.18131/g3-7wfq-4a89\"],\"ARK\":null,\"Id\":\"c45d0ab0-3fe2-404f-bc37-04de53ccf095\",\"File Size\":135197,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/c45d0ab0-3fe2-404f-bc37-04de53ccf095\",\"download\":\"https://digitalhub.northwestern.edu/downloads/c45d0ab0-3fe2-404f-bc37-04de53ccf095\"},{\"Title\":[\"Technology-Enabled Prevention Services for At-Risk Youth. Design Session Child Assent Parent Consent\"],\"Resource type(s)\":[\"Forms\"],\"Keyword\":[\"Digital Mental Health\",\"Children\",\"Technology Enabled Services\",\"Consent\",\"Design\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2020\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Anxiety Disorders--prevention \\u0026 control\",\"Digital Technology\",\"Adolescent\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":[\"This research is supported by Northwestern University and the National Institute of Mental Health.\"],\"DOI\":[\"doi:10.18131/g3-eqnc-sg02\"],\"ARK\":null,\"Id\":\"8095347b-5b41-4bdb-82dc-031301e8f7a6\",\"File Size\":125876,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/8095347b-5b41-4bdb-82dc-031301e8f7a6\",\"download\":\"https://digitalhub.northwestern.edu/downloads/8095347b-5b41-4bdb-82dc-031301e8f7a6\"},{\"Title\":[\"Technology-Enabled Prevention Services for At-Risk Youth. Design Session Staff Consent\"],\"Resource type(s)\":[\"Forms\"],\"Keyword\":[\"Digital Mental Health\",\"Children\",\"Consent\",\"Technology Enabled Services\",\"Design\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2020\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Anxiety Disorders--prevention \\u0026 control\",\"Digital Technology\",\"Adolescent\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":[\"This research is supported by Northwestern University and the National Institute of Mental Health. \"],\"DOI\":[\"doi:10.18131/g3-sqds-5x90\"],\"ARK\":null,\"Id\":\"d1899d92-00ed-4018-8f53-a6bab4e64d68\",\"File Size\":124389,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/d1899d92-00ed-4018-8f53-a6bab4e64d68\",\"download\":\"https://digitalhub.northwestern.edu/downloads/d1899d92-00ed-4018-8f53-a6bab4e64d68\"},{\"Title\":[\"Technology-Enabled Prevention Services for At-Risk Youth. Protocol\"],\"Resource type(s)\":[\"Study Design\"],\"Keyword\":[\"Digital Mental Health\",\"Children\",\"Technology Enabled Services\",\"IRB Protocol\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2020-12-03\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Anxiety Disorders--prevention \\u0026 control\",\"Digital Technology \",\"Adolescent\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":null,\"DOI\":[\"doi:10.18131/g3-t82p-5q82\"],\"ARK\":null,\"Id\":\"552ea67e-b9ca-4f5e-b72c-d5ae77a579c0\",\"File Size\":388651,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/552ea67e-b9ca-4f5e-b72c-d5ae77a579c0\",\"download\":\"https://digitalhub.northwestern.edu/downloads/552ea67e-b9ca-4f5e-b72c-d5ae77a579c0\"},{\"Title\":[\"Technology-Enabled Prevention Services for At-Risk Youth. Usability Lab Adult Consent\"],\"Resource type(s)\":[\"Forms\"],\"Keyword\":[\"Digital Mental Health\",\"Children\",\"Technology Enabled Services\",\"Consent\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2020\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Anxiety Disorders--prevention \\u0026 control\",\"Digital Technology\",\"Adolescent\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":[\"This research is supported by Northwestern University and the National Institute of Mental Health. \"],\"DOI\":[\"doi:10.18131/g3-sefc-7421\"],\"ARK\":null,\"Id\":\"e7624d02-804c-4a12-a0a6-353fb10da1f0\",\"File Size\":124721,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/e7624d02-804c-4a12-a0a6-353fb10da1f0\",\"download\":\"https://digitalhub.northwestern.edu/downloads/e7624d02-804c-4a12-a0a6-353fb10da1f0\"},{\"Title\":[\"Technology-Enabled Prevention Services for At-Risk Youth. Usability Lab Child Assent Parent Consent\"],\"Resource type(s)\":[\"Forms\"],\"Keyword\":[\"Digital Mental Health\",\"Children\",\"Technology Enabled Services\",\"Consent\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2020\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Anxiety Disorders--prevention \\u0026 control\",\"Digital Technology\",\"Adolescent\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":[\"This research is supported by Northwestern University and the National Institute of Mental Health.\"],\"DOI\":[\"doi:10.18131/g3-t3rb-4688\"],\"ARK\":null,\"Id\":\"ea60cd4d-1db0-4eb1-a5a4-068fedc70798\",\"File Size\":126850,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/ea60cd4d-1db0-4eb1-a5a4-068fedc70798\",\"download\":\"https://digitalhub.northwestern.edu/downloads/ea60cd4d-1db0-4eb1-a5a4-068fedc70798\"},{\"Title\":[\"Technology-Enabled Prevention Services for At-Risk Youth. Usability Lab Staff Consent\"],\"Resource type(s)\":[\"Forms\"],\"Keyword\":[\"Digital Mental Health\",\"Children\",\"Technology Enabled Services\",\"Consent\"],\"Rights\":[\"http://creativecommons.org/licenses/by/3.0/us/\"],\"Creator\":[\"Center for Behavioral Intervention Technologies, Department\"],\"Contributor\":null,\"Description\":null,\"Abstract\":null,\"Original Bibliographic Citation\":null,\"Related URL\":null,\"Publisher\":[\"DigitalHub. Galter Health Sciences Library \\u0026 Learning Center\"],\"Date Created\":[\"2020\"],\"Original Identifier\":null,\"Language\":[\"English\"],\"Subject: MESH\":[\"Anxiety Disorders--prevention \\u0026 control\",\"Digital Technology\",\"Adolescent\"],\"Subject: LCSH\":null,\"Subject: Geographic Name\":null,\"Subject: Name\":null,\"Location\":null,\"Digital Origin\":null,\"Page Number\":null,\"Acknowledgments\":null,\"Grants And Funding\":[\"This research is supported by Northwestern University and the National Institute of Mental Health.\"],\"DOI\":[\"doi:10.18131/g3-f7qb-4t30\"],\"ARK\":null,\"Id\":\"0043bb90-7350-423c-9894-e1d60f40b7dd\",\"File Size\":124009,\"File Format\":[\"pdf (Portable Document Format)\"],\"uri\":\"https://digitalhub.northwestern.edu/files/0043bb90-7350-423c-9894-e1d60f40b7dd\",\"download\":\"https://digitalhub.northwestern.edu/downloads/0043bb90-7350-423c-9894-e1d60f40b7dd\"}]}\n",
    "\n",
    "                              \n",
    "# current_list_3=[]\n",
    "# current_series_3 = digitalhub_community_df.loc[digitalhub_community_df['Id'] == '27114af7-6444-4f3c-8de1-3e9c5dc73e95','members']\n",
    "# # print(current_series_3.item()[0])\n",
    "# current_list_3 = current_series_3.tolist()\n",
    "# cbits_result = []\n",
    "# cbits_result = current_series_3.item() + [x for x in add_to_series_3 if x not in current_series_3.items()]\n",
    "# print(len(cbits_result))\n",
    "# # print(cbits_result)\n",
    "                            \n",
    "## Add CBITS result back to member\n",
    "\n",
    "# digitalhub_community_df['members'] = digitalhub_community_df['members'].astype('object')\n",
    "# digitalhub_community_df.at[8,'members'] = cbits_result  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################################\n",
    "### Remove subcollections from GHSL###\n",
    "#####################################\n",
    "\n",
    "## Remove Old GV Black (is not migrated)\n",
    "## x633f100h\n",
    "\n",
    "print(len(ghsl_result))\n",
    "for i in range(len(ghsl_result)):\n",
    "#     print(i)\n",
    "    if ghsl_result[i]['Id'] == 'x633f100h':\n",
    "        print(\"True\")\n",
    "        del ghsl_result[i]\n",
    "        break\n",
    "\n",
    "\n",
    "#### Remove Special Collections (include in various communities)\n",
    "## v405s9425\n",
    "\n",
    "    ##Subcollection: Notables \n",
    "    ## ed35d953-d035-44a7-bacb-0edf1c8006a6\n",
    "    ## Becomes Community:  Endowed Professorship Biographies\n",
    "\n",
    "    ##Subcollection: Oral Histories\n",
    "    ## oral-histories\n",
    "    ## Becomes Community: AV Archives\n",
    "\n",
    "    ##Subcollection: Paul de Kruif Interviews\n",
    "    ## paul-de-kruif-interviews\n",
    "    ## Becomes Community: AV Archives\n",
    "\n",
    "    ##Subcollection: Special Collections - art\n",
    "    ## 2f75r807r\n",
    "    ## Becomes Community: History of FSM\n",
    "\n",
    "    ##Subcollection: Special Collections - photos from the vault\n",
    "    ## 5712m6524\n",
    "    ## Becomes Communitiy: History of FSM\n",
    "\n",
    "    ##Subcollection: Student Life\n",
    "    ## student-life\n",
    "    ## Becomes Community: AV Archives\n",
    "\n",
    "print(len(ghsl_result))\n",
    "for i in range(len(ghsl_result)):\n",
    "#     print(i)\n",
    "    if ghsl_result[i]['Id'] == 'v405s9425':\n",
    "        print(\"True\")\n",
    "        del ghsl_result[i]\n",
    "        break\n",
    "    \n",
    "#### Remove 12th General hospital collection (becomes own community)\n",
    "## 07b25bee-4a47-466a-b9b8-70d7a392fab0\n",
    "## Becomes own community\n",
    "\n",
    "print(len(ghsl_result))\n",
    "for i in range(len(ghsl_result)):\n",
    "#     print(i)\n",
    "    if ghsl_result[i]['Id'] == '07b25bee-4a47-466a-b9b8-70d7a392fab0':\n",
    "        print(\"True\")\n",
    "        del ghsl_result[i]\n",
    "        break\n",
    "\n",
    "#### Remove Northwestern University Medical School 1859-1979\n",
    "## areybook\n",
    "## Becomes Community: History of FSM\n",
    "\n",
    "print(len(ghsl_result))\n",
    "for i in range(len(ghsl_result)):\n",
    "#     print(i)\n",
    "    if ghsl_result[i]['Id'] == 'areybook':\n",
    "        print(\"True\")\n",
    "        del ghsl_result[i]\n",
    "        break\n",
    "\n",
    "        \n",
    "#################################################\n",
    "## Add private files to COVID-19 Collection ####\n",
    "################################################\n",
    "\n",
    "add_to_series_path_1 = r\"data\\community\\private_covid_19_design of.txt\"\n",
    "add_to_series_path_2 = r\"data\\community\\private_covid_19_illustrated_state_of.txt\"\n",
    "add_to_series_path_3 = r\"data\\community\\private_covid_19_real_time_UV.txt\"\n",
    "\n",
    "covid_private_path_list = [add_to_series_path_1, \n",
    "                          add_to_series_path_2,\n",
    "                          add_to_series_path_3]\n",
    "\n",
    "covid_private_list = [] \n",
    "\n",
    "for path in covid_private_path_list: \n",
    "    with open(path, 'r', encoding= 'utf8') as f:\n",
    "        s = f.read()    \n",
    "        result = json.loads(s)   # try to parse...\n",
    "        covid_private_list.append(result)\n",
    "\n",
    "\n",
    "## Create a list from the existing members column for the collection\n",
    "current_list_4=[]\n",
    "current_series_4 = digitalhub_community_df.loc[digitalhub_community_df['Id'] == '3635f61e-e67e-41f2-b4de-982a9f81dcc8','members']\n",
    "# print(current_series_4.item()[0])\n",
    "\n",
    "# ## Likely don't need to convert it to a list\n",
    "# current_list_4 = current_series_4.tolist()\n",
    "\n",
    "##Add items from covid_private_list list to current_series\n",
    "covid_result = []\n",
    "covid_result = current_series_4.item() + [x for x in covid_private_list if x not in current_series_4.items()]\n",
    "print(len(covid_result))\n",
    "# print(covid_result)\n",
    "                            \n",
    "# Add COVID result back to member\n",
    "\n",
    "digitalhub_community_df['members'] = digitalhub_community_df['members'].astype('object')\n",
    "digitalhub_community_df.at[28,'members'] = covid_result  \n",
    "\n",
    "\n",
    "#################################################################\n",
    "## Add private files to Masters in Public Health CE Products ####\n",
    "################################################################\n",
    "\n",
    "add_to_series_path_5_0 = r\"data\\community\\private_masters_trends_in.txt\"\n",
    "\n",
    "masters_private_path_list = [add_to_series_path_5_0]\n",
    "                                                   \n",
    "\n",
    "masters_private_list = [] \n",
    "\n",
    "for path in masters_private_path_list: \n",
    "    with open(path, 'r', encoding= 'utf8') as f:\n",
    "        s = f.read()    \n",
    "        result = json.loads(s)   # try to parse...\n",
    "        masters_private_list.append(result)\n",
    "\n",
    "\n",
    "## Create a list from the existing members column for the collection\n",
    "current_series_5_0 = digitalhub_community_df.loc[digitalhub_community_df['Id'] == '40acd700-b850-4e7b-a650-0535de84ab6b','members']\n",
    "# print(current_series_5_0.item()[0])\n",
    "\n",
    "##Add items from private_list to current_series\n",
    "masters_result = []\n",
    "masters_result = current_series_5_0.item() + [x for x in masters_private_list if x not in current_series_5_0.items()]\n",
    "print(len(masters_result))\n",
    "# print(masters_result)\n",
    "                            \n",
    "# Add result back to member\n",
    "\n",
    "digitalhub_community_df['members'] = digitalhub_community_df['members'].astype('object')\n",
    "digitalhub_community_df.at[5,'members'] = masters_result   \n",
    "\n",
    "#################################################################\n",
    "## Add private files to CPIM ####\n",
    "################################################################\n",
    "\n",
    "add_to_series_path_6_0 = r\"data\\community\\private_centerforprevention_smithegan.txt\"\n",
    "\n",
    "cpim_private_path_list = [add_to_series_path_6_0\n",
    "                                                   ]\n",
    "\n",
    "cpim_private_list = [] \n",
    "\n",
    "for path in cpim_private_path_list: \n",
    "    with open(path, 'r', encoding= 'utf8') as f:\n",
    "        s = f.read()    \n",
    "        result = json.loads(s)   # try to parse...\n",
    "        cpim_private_list.append(result)\n",
    "\n",
    "\n",
    "## Create a list from the existing members column for the collection\n",
    "current_series_6_0 = digitalhub_community_df.loc[digitalhub_community_df['Id'] == '6682x398c','members']\n",
    "# print(current_series_6_0.item()[0])\n",
    "\n",
    "##Add items from private_list list to current_series\n",
    "cpim_result = current_series_6_0.item() + [x for x in cpim_private_list if x not in current_series_6_0.items()]\n",
    "print(len(cpim_result))\n",
    "# print(cpim_result)\n",
    "                            \n",
    "# Add result back to member\n",
    "\n",
    "digitalhub_community_df['members'] = digitalhub_community_df['members'].astype('object')\n",
    "digitalhub_community_df.at[9,'members'] = cpim_result   \n",
    "\n",
    "#################################################################\n",
    "## Add private files to National Center for Data to Health ####\n",
    "################################################################\n",
    "\n",
    "add_to_series_path_7_0 = r\"data\\community\\private_centerfordatatohealth_invenio.txt\"\n",
    "\n",
    "centerdata_private_path_list = [add_to_series_path_7_0]\n",
    "\n",
    "centerdata_private_list = [] \n",
    "\n",
    "for path in centerdata_private_path_list: \n",
    "    with open(path, 'r', encoding= 'utf8') as f:\n",
    "        s = f.read()    \n",
    "        result = json.loads(s)   # try to parse...\n",
    "        centerdata_private_list.append(result)\n",
    "\n",
    "\n",
    "## Create a list from the existing members column for the collection\n",
    "current_series_7_0 = digitalhub_community_df.loc[digitalhub_community_df['Id'] == 'b0375b45-0b95-4bf8-9ee7-7df4d6fb47e4','members']\n",
    "# print(current_series_7_0.item()[0])\n",
    "\n",
    "##Add items from private_list list to current_series\n",
    "centerdata_result = current_series_7_0.item() + [x for x in centerdata_private_list if x not in current_series_7_0.items()]\n",
    "print(len(centerdata_result))\n",
    "# print(centerdata_result)\n",
    "                            \n",
    "# Add result back to member\n",
    "\n",
    "digitalhub_community_df['members'] = digitalhub_community_df['members'].astype('object')\n",
    "digitalhub_community_df.at[6,'members'] = centerdata_result   \n",
    "\n",
    "#################################################################\n",
    "## Add private file to History of Feinberg School of Medicine ####\n",
    "################################################################\n",
    "\n",
    "add_to_series_path_11_0 = r\"data\\community\\private_feinberghistory_mcclintock.txt\"\n",
    "\n",
    "feinberg_private_path_list = [add_to_series_path_11_0]\n",
    "\n",
    "feinberg_private_list = [] \n",
    "\n",
    "for path in feinberg_private_path_list: \n",
    "    with open(path, 'r', encoding= 'utf8') as f:\n",
    "        s = f.read()    \n",
    "        result = json.loads(s)   # try to parse...\n",
    "        feinberg_private_list.append(result)\n",
    "\n",
    "\n",
    "## Create a list from the existing members column for the collection\n",
    "current_series_11_0 = digitalhub_community_df.loc[digitalhub_community_df['Id'] == 'history-of-feinberg-school-of-medicine','members']\n",
    "# print(current_series_11_0.item()[0])\n",
    "\n",
    "##Add items from private_list list to current_series\n",
    "feinberg_result = current_series_11_0.item() + [x for x in centerdata_private_list if x not in current_series_11_0.items()]\n",
    "print(len(feinberg_result))\n",
    "# print(feinberg_result)\n",
    "                            \n",
    "# Add result back to member\n",
    "\n",
    "digitalhub_community_df['members'] = digitalhub_community_df['members'].astype('object')\n",
    "digitalhub_community_df.at[34,'members'] = feinberg_result   \n",
    "\n",
    "## Resources\n",
    "## https://stackoverflow.com/questions/26483254/python-pandas-insert-list-into-a-cell\n",
    "## https://www.geeksforgeeks.org/python-removing-dictionary-from-list-of-dictionaries/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b1c495",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspect the \"members\" column and create a list of member IDs\n",
    "\n",
    "row_member_list = []\n",
    "column_member ={}\n",
    "count_member = {}\n",
    "\n",
    "for k, v in digitalhub_community_df[\"members\"].items():\n",
    "    for value in v: \n",
    "        member = value[\"Id\"]\n",
    "        row_member_list.append(member)\n",
    "    column_member[k] = row_member_list\n",
    "    count_member[k] = len(row_member_list)\n",
    "    row_member_list =[]\n",
    "    row_member_count = []\n",
    "\n",
    "## Append the column member dictionary to the DigitalHub Community DF dataframe\n",
    "\n",
    "digitalhub_community_df['Member_List'] = digitalhub_community_df.index.map(column_member)\n",
    "digitalhub_community_df['Member_List_Count'] = digitalhub_community_df.index.map(count_member)\n",
    "digitalhub_community_df.head()\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0d4207",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export file to excel, with the Pandas index, and with the headers\n",
    "\n",
    "digitalhub_community_df.to_excel(\"outputs/digitalhub_community_df.xlsx\", header=True)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c0b45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a dataframe for each members row and concatenate all of these into one digitalHub_sub_collection_df\n",
    "\n",
    "members_dfs_list = []\n",
    "\n",
    "for k, v in digitalhub_community_df[\"members\"].items():\n",
    "#     print(\"this is k: \", k)\n",
    "#     print(\"this is v: \", v)\n",
    "    member_df = pd.json_normalize(v)\n",
    "    member_df['community_rowid'] = k\n",
    "    members_dfs_list.append(member_df)\n",
    "\n",
    "digitalhub_sub_collection_df = pd.concat(members_dfs_list, sort=False).reset_index(drop='index')\n",
    "digitalhub_sub_collection_df.head()\n",
    "\n",
    "## Resource\n",
    "## https://stackoverflow.com/questions/62816027/convert-pandas-json-column-to-multiple-rows\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef79ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove lists (i.e. brackets) and convert to strings for data in each column\n",
    "\n",
    "# def list2Str(lst):\n",
    "#     if type(lst) is list: # apply conversion to list columns\n",
    "#         return\";\".join(lst)\n",
    "#     else:\n",
    "#         return str\n",
    "\n",
    "# digitalhub_sub_collection_df.apply(lambda x: [list2Str(i) for i in x])\n",
    "\n",
    "# digitalhub_sub_collection_df.head()\n",
    "\n",
    "## Resources\n",
    "## https://stackoverflow.com/questions/38147447/how-to-remove-square-bracket-from-pandas-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9432c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add Column to digitalhub_sub_collection_df to indicate that these results are a sub_collection or a record\n",
    "\n",
    "# digitalhub_sub_collection_df[\"Level\"] =  \"Collection\"\n",
    "\n",
    "digitalhub_sub_collection_df['Level Type'] = np.where(digitalhub_sub_collection_df['DOI'].isnull(),\"Sub_Collection\", \"Record\" )\n",
    "digitalhub_sub_collection_df['Level Number'] = np.where(digitalhub_sub_collection_df['DOI'].isnull(),\"2\", \"6\" )\n",
    "digitalhub_sub_collection_df['Level Number'] = digitalhub_sub_collection_df['Level Number'].apply(int)\n",
    "\n",
    "# digitalhub_sub_collection_df.dtypes\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc908e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export file to excel, without the Pandas index, but with the header\n",
    "digitalhub_sub_collection_df.to_excel(\"outputs/digitalhub_sub_collection_df.xlsx\", index=False, header=True)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e7da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate the digitalhub_community_df to the digitalhub_sub_collection_df using the 'community_rowid'\n",
    "digitalhub_comm_col_df = pd.concat([digitalhub_community_df, digitalhub_sub_collection_df], axis=0).sort_values(by=['community_rowid'])\n",
    "digitalhub_comm_col_df .reset_index(inplace=True, drop=True) \n",
    "# digitalhub_comm_col_df.head()\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6880080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort the dataframe by rowid and Level Number\n",
    "digitalhub_comm_col_df.sort_values(by = ['community_rowid','Level Number'], ascending = [True, True], inplace=True)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6559530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Fill forward the Community ID into subcollections and records\n",
    "digitalhub_comm_col_df['Community_ID'] = digitalhub_comm_col_df.groupby(['community_rowid'])['Community_ID'].ffill()\n",
    "\n",
    "## Resources\n",
    "## https://stackoverflow.com/questions/64795941/how-do-i-forward-fill-nas-with-condition-of-2-other-cells-being-equal-in-pandas\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b834667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a column for Sub_Collection ID\n",
    "digitalhub_comm_col_df['Sub_Collection_ID'] = np.where(digitalhub_comm_col_df['Level Type'] == 'Sub_Collection',digitalhub_comm_col_df['Id'], np.nan)\n",
    "\n",
    "## Resources: \n",
    "## https://stackoverflow.com/questions/67043249/how-to-use-np-where-in-creating-new-column-using-previous-rows\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f1f0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export file to excel, without the Pandas index, but with the header\n",
    "digitalhub_comm_col_df.to_excel(\"outputs/digitalhub_comm_col_df.xlsx\", index=False, header=True)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe23960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6d07474",
   "metadata": {},
   "source": [
    "##### Recall Sub_Collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3bc773",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract a the series for sub_collection 'ids' and transform into a list\n",
    "\n",
    "digitalhub_sub_collection_series = digitalhub_comm_col_df[digitalhub_comm_col_df[\"Level Type\"] == \"Sub_Collection\"]['Id']\n",
    "digitalhub_sub_collection_list = digitalhub_sub_collection_series.tolist()\n",
    "\n",
    "print(digitalhub_sub_collection_list)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507aa217",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop through list of DigitalHub Sub_Collections and use the urllib.request to get the json data\n",
    "## test_list = ['2cc92425-b656-47ea-a3b4-825405ee6088', 'a86e1412-d72c-4cae-b8ca-16fd834cb128','fc389d13-2430-409b-82fd-a4b26613d350']\n",
    "\n",
    "multi_digitalhub_sub_collection_list = []\n",
    "digitalhub_sub_collection_problem_list = []\n",
    "\n",
    "for item in digitalhub_sub_collection_list:\n",
    "    try:\n",
    "\n",
    "        with urllib.request.urlopen(f\"https://digitalhub.northwestern.edu/collections/{item}.json\" ) as url:\n",
    "            single_digitalhub_sub_collection_dict = json.loads(url.read().decode())\n",
    "            multi_digitalhub_sub_collection_list.append(single_digitalhub_sub_collection_dict)\n",
    "            print(item)\n",
    "        time.sleep(1)\n",
    "       \n",
    "\n",
    "    except urllib.error.HTTPError as http_err:\n",
    "        print(item)\n",
    "        digitalhub_sub_collection_problem_list.append(item)\n",
    "        print(f'HTTP error occurred: {http_err}')  # Python 3.6\n",
    "        \n",
    "\n",
    "    except urllib.error.URLError as url_err:\n",
    "        print(item)\n",
    "        digitalhub_sub_collection_problem_list.append(item)\n",
    "        print(f'URL error occurred: {url_err}. ', 'Exiting the loop!')  # Python 3.6\n",
    "       \n",
    "\n",
    "    except json.JSONDecodeError as json_err:\n",
    "        print(item)\n",
    "        digitalhub_sub_collection_problem_list.append(item)\n",
    "        print(f'JSON Decode error occurred: {json_err}. ', 'Poorly formed JSON.')  # Python 3.6\n",
    "       \n",
    "        \n",
    "    except Exception as err:\n",
    "        print(item)\n",
    "        digitalhub_sub_collection_problem_list.append(item)\n",
    "        print(f'Other error occurred: {err}. ')  # Python 3.6\n",
    "        \n",
    "        \n",
    "       \n",
    "    else:\n",
    "        print('Success!')\n",
    "\n",
    "\n",
    "\n",
    "## Resources\n",
    "## https://docs.python.org/3/library/urllib.request.html\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21908ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspect the results of the URL Query for DigitalHub Collections that will become communities in Prism\n",
    "\n",
    "# print(multi_digitalhub_sub_collection_list)\n",
    "print(len(digitalhub_sub_collection_problem_list))\n",
    "print(digitalhub_sub_collection_problem_list)\n",
    "\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa6d91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create and export dataframe for problem list\n",
    "problem_df_2 = pd.DataFrame(digitalhub_sub_collection_problem_list)\n",
    "\n",
    "## Export file to excel, without the Pandas index, but with the header\n",
    "problem_df_2.to_excel(\"outputs/problem_df_2.xlsx\", index=False, header=True)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e86dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a dataframe called digitalhub_sub_collection_recall_df from DigitalHub json for DigitalHub Sub_Collections\n",
    "\n",
    "digitalhub_sub_collection_recall_df = pd.DataFrame.from_dict(json_normalize(multi_digitalhub_sub_collection_list, max_level=1))\n",
    "digitalhub_sub_collection_recall_df.head(10)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb9dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Upload .txt files of the problem Sub_Collection json metadata\n",
    "\n",
    "\n",
    "## 1. Problem with: 91294b2e-34e4-46ac-9086-be17c40d0d01\n",
    "operation_path = r\"data\\sub_collection\\operation.txt\"\n",
    "\n",
    "## 2. Problem with: 4dde1545-ad4e-4801-9db8-02d5aadc38c6\n",
    "# template_7 = r\"data\\sub_collection\\template_7.txt\"\n",
    "\n",
    "## 3. Problem with: 1724d997-42e2-493d-88fd-22f836403628\n",
    "# template_6 = r\"data\\sub_collection\\template_6.txt\"\n",
    "\n",
    "## 4. Problem with: a76c9405-2fb7-47c0-bd6e-cd8cf9ea69a8\n",
    "# template_5 = r\"data\\sub_collection\\template_5.txt\"\n",
    "\n",
    "## 5. Problem with: ef9651c9-c810-42e0-8e2d-58993586473d\n",
    "# template_4 = r\"data\\sub_collection\\template_4.txt\"\n",
    "\n",
    "## 6. Problem with: 779a5d4d-23b4-4a28-8c38-48faa43de46d\n",
    "# template_3 = r\"data\\sub_collection\\template_3.txt\"\n",
    "\n",
    "## 6. Problem with: 8c462e3c-4666-4997-9a29-4c17f7846c96\n",
    "# template_2 = r\"data\\sub_collection\\template_2.txt\"\n",
    "\n",
    "## 7. Problem with: 22e29a25-6e89-4322-b772-15442ca5b713\n",
    "t_series_path = r\"data\\sub_collection\\t_series.txt\"\n",
    "\n",
    "## 8. Problem with: 2abe2c1b-932e-4bb0-8455-a97d828f6924\n",
    "sample_path = r\"data\\sub_collection\\sample_.txt\"\n",
    "\n",
    "## 9. Problem with:4a8457cb-7a65-4774-9ab6-057702e521f5\n",
    "r_series_path = r\"data\\sub_collection\\r_series.txt\"\n",
    "\n",
    "## 10. Problem with: 90c63af3-adb9-48dc-95d9-7b4bafe13a7a\n",
    "k_series_path = r\"data\\sub_collection\\k_series.txt\"\n",
    "\n",
    "## 11. Problem with: 01b2ba97-8603-477f-bde3-b36b6c79bdea\n",
    "industry_path = r\"data\\sub_collection\\industry.txt\"\n",
    "\n",
    "## 12. Problem with: 691ddbbd-785c-4a6a-85d1-7569d8fcbcdb\n",
    "grant_resources_path = r\"data\\sub_collection\\grant_resources.txt\"\n",
    "\n",
    "## 13.Problem with: 9aa9dbb6-7971-4e5c-9b9c-81216d9325d3\n",
    "federal_non_nih_path = r\"data\\sub_collection\\federal_non_nih.txt\"\n",
    "\n",
    "## 14. PRoblem with: 1b2b7d0f-d7f3-41a4-a2a4-8435d719ecec\n",
    "f_series_path = r\"data\\sub_collection\\f_series.txt\"\n",
    "\n",
    "## 15. Problem with: 46374bec-fe29-4a06-a8b8-f1f93668699c\n",
    "archive_path = r\"data\\sub_collection\\archive.txt\"\n",
    "\n",
    "## 16. Problem with: eaa0acc4-64b5-4c34-8e90-49537ffa9e0b\n",
    "u_series_path = r\"data\\sub_collection\\u_series.txt\"\n",
    "\n",
    "## 17. PRoblem with: 6ce6bf89-1c23-4949-9ae3-1c6bd874e593\n",
    "# template_9 = r\"data\\sub_collection\\template_9.txt\"\n",
    "\n",
    "## 18. PRoblem with: 113b8ab8-8f40-454b-9932-abd83e392f78\n",
    "# template_8 = r\"data\\sub_collection\\template_8.txt\"\n",
    "\n",
    "## 19. Problem with: student-life\n",
    "student_life_path = r\"data\\sub_collection\\student_life.txt\"\n",
    "\n",
    "## 20. Problem with: paul-de-kruif-interviews\n",
    "paul_interview_path = r\"data\\sub_collection\\paul_interview.txt\"\n",
    "\n",
    "\n",
    "\n",
    "problem_sub_dict_list = []\n",
    "\n",
    "path_sub_list = [operation_path, \n",
    "#                  template_7, \n",
    "#                  template_6, \n",
    "#                  template_5, \n",
    "#                  template_4, \n",
    "#                  template_3, \n",
    "#                  template_2, \n",
    "                 t_series_path,\n",
    "                 sample_path,\n",
    "                 r_series_path,\n",
    "                 k_series_path,\n",
    "                 industry_path,\n",
    "                 grant_resources_path,\n",
    "                 federal_non_nih_path, \n",
    "                 f_series_path,\n",
    "                 archive_path,  \n",
    "                 u_series_path, \n",
    "#                  template_8, \n",
    "#                  template_9, \n",
    "                 student_life_path, \n",
    "                 paul_interview_path]\n",
    "\n",
    "for path in path_sub_list: \n",
    "#     print(path)\n",
    "    with open(path, 'r', encoding= 'utf8') as f:\n",
    "        s = f.read()\n",
    "#         problem_sub_dict = json.loads(data)\n",
    "#         problem_sub_dict_list.append(problem_sub_dict)\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                result = json.loads(s)   # try to parse...\n",
    "                break                    # parsing worked -> exit loop\n",
    "            except Exception as e:\n",
    "                # \"Expecting , delimiter: line 34 column 54 (char 1158)\"\n",
    "                # position of unexpected character after '\"'\n",
    "                unexp = int(re.findall(r'\\(char (\\d+)\\)', str(e))[0])\n",
    "                # position of unescaped '\"' before that\n",
    "                unesc = s.rfind(r'\"', 0, unexp)\n",
    "                s = s[:unesc] + r'\\\"' + s[unesc+1:]\n",
    "                # position of correspondig closing '\"' (+2 for inserted '\\')\n",
    "                closg = s.find(r'\"', unesc + 2)\n",
    "                s = s[:closg] + r'\\\"' + s[closg+1:]\n",
    "#         print(result)\n",
    "        problem_sub_dict_list.append(result)\n",
    "\n",
    "\n",
    "## Resources\n",
    "## https://stackoverflow.com/questions/16573332/jsondecodeerror-expecting-value-line-1-column-1-char-0\n",
    "## https://stackoverflow.com/questions/18514910/how-do-i-automatically-fix-an-invalid-json-string\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adc7361",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a problem_sub_df to hold the problem_sub_dict_list\n",
    "problem_sub_df = pd.DataFrame.from_dict(json_normalize(problem_sub_dict_list, max_level=1))\n",
    "problem_sub_df.head()\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdd4898",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate the DigitalHub Community Dataframe to the problem_sub_df\n",
    "\n",
    "digitalhub_sub_collection_recall_df = pd.concat([digitalhub_sub_collection_recall_df, problem_sub_df], axis=0)\n",
    "digitalhub_sub_collection_recall_df.reset_index(inplace=True, drop=True) \n",
    "digitalhub_sub_collection_recall_df.head(10)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6b6708",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add Column to digitalhub_sub_collection_df to indicate that these results are a sub_collection\n",
    "digitalhub_sub_collection_recall_df[\"Level Type\"] = \"Sub_Collection\"\n",
    "digitalhub_sub_collection_recall_df[\"Level Number\"] = \"2\"\n",
    "digitalhub_sub_collection_recall_df['Level Number'] = digitalhub_sub_collection_recall_df['Level Number'].apply(int)\n",
    "\n",
    "## Create a column from the index\n",
    "digitalhub_sub_collection_recall_df['sub_collection_rowid'] = digitalhub_sub_collection_recall_df.index\n",
    "\n",
    "## Create a new column called Sub_Collection_ID\n",
    "digitalhub_sub_collection_recall_df['Sub_Collection_ID'] = digitalhub_sub_collection_recall_df['Id']\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d908c53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "##### Add records to sub-collection || Add sub_sub_collections to sub_collection ####\n",
    "#####################################################################################\n",
    "\n",
    "#################################################################################\n",
    "## Add private files to NUCATS Grants Repository --> K-Series Sub_Collection ####\n",
    "################################################################################\n",
    "\n",
    "# add_to_series_path_5 = r\"data\\sub_collection\\private_nucats_grants_k-series_tunc_ozcan.txt\"\n",
    "\n",
    "# k_series_private_path_list = [add_to_series_path_5]\n",
    "\n",
    "# k_series_private_list = [] \n",
    "\n",
    "# for path in k_series_private_path_list: \n",
    "#     with open(path, 'r', encoding= 'utf8') as f:\n",
    "#         s = f.read()    \n",
    "#         result = json.loads(s)   # try to parse...\n",
    "#         k_series_private_list.append(result)\n",
    "\n",
    "\n",
    "# ## Create a list from the existing members column for the collection\n",
    "# current_list_5=[]\n",
    "# current_series_5 = digitalhub_sub_collection_recall_df.loc[digitalhub_sub_collection_recall_df['Id'] == '90c63af3-adb9-48dc-95d9-7b4bafe13a7a','members']\n",
    "# #print(current_series_5.item()[0])\n",
    "\n",
    "# ##Add items from k_series_private_list list to current_series\n",
    "# k_series_result = []\n",
    "# k_series_result = current_series_5.item() + [x for x in k_series_private_list if x not in current_series_5.items()]\n",
    "# print(len(k_series_result))\n",
    "# # print(k_series_result)\n",
    "                            \n",
    "# # Add k_series_result back to member\n",
    "\n",
    "# digitalhub_sub_collection_recall_df['members'] = digitalhub_sub_collection_recall_df['members'].astype('object')\n",
    "# digitalhub_sub_collection_recall_df.at[92,'members'] = k_series_result  \n",
    "\n",
    "\n",
    "#################################################################################\n",
    "## Add private files to GHSL --> DIAW ####\n",
    "################################################################################\n",
    "\n",
    "add_to_series_path_6 = r\"data\\sub_collection\\private_ghsl_diaw_scientists_in_media.txt\"\n",
    "\n",
    "diaw_private_path_list = [add_to_series_path_6]\n",
    "\n",
    "diaw_private_list = [] \n",
    "\n",
    "for path in diaw_private_path_list: \n",
    "    with open(path, 'r', encoding= 'utf8') as f:\n",
    "        s = f.read()    \n",
    "        result = json.loads(s)   # try to parse...\n",
    "        diaw_private_list.append(result)\n",
    "\n",
    "\n",
    "## Create a list from the existing members column for the collection\n",
    "current_list_6=[]\n",
    "current_series_6 = digitalhub_sub_collection_recall_df.loc[digitalhub_sub_collection_recall_df['Id'] == 'diaw2017','members']\n",
    "#print(current_series_6.item()[0])\n",
    "\n",
    "##Add items from k_series_private_list list to current_series\n",
    "diaw_result = []\n",
    "diaw_result = current_series_6.item() + [x for x in diaw_private_list if x not in current_series_6.items()]\n",
    "print(len(diaw_result))\n",
    "# print(k_series_result)\n",
    "                            \n",
    "# Add k_series_result back to member\n",
    "\n",
    "digitalhub_sub_collection_recall_df['members'] = digitalhub_sub_collection_recall_df['members'].astype('object')\n",
    "digitalhub_sub_collection_recall_df.at[7,'members'] = diaw_result\n",
    "\n",
    "#################################################################################\n",
    "### Add private files to Science in Society --> 2018 ####\n",
    "################################################################################\n",
    "\n",
    "add_to_series_path_7 = r\"data\\sub_collection\\private_science_in_society_2018_mouse_egg.txt\"\n",
    "\n",
    "sis_private_path_list = [add_to_series_path_7]\n",
    "\n",
    "sis_private_list = [] \n",
    "\n",
    "for path in sis_private_path_list: \n",
    "    with open(path, 'r', encoding= 'utf8') as f:\n",
    "        s = f.read()    \n",
    "        result = json.loads(s)   # try to parse...\n",
    "        sis_private_list.append(result)\n",
    "\n",
    "\n",
    "## Create a list from the existing members column for the collection\n",
    "current_list_7=[]\n",
    "current_series_7 = digitalhub_sub_collection_recall_df.loc[digitalhub_sub_collection_recall_df['Id'] == '9e27fbd0-c6cb-47c7-8770-8ffeb135009d','members']\n",
    "#print(current_series_7.item()[0])\n",
    "\n",
    "##Add items from k_series_private_list list to current_series\n",
    "sis_result = []\n",
    "diaw_result = current_series_7.item() + [x for x in sis_private_list if x not in current_series_7.items()]\n",
    "print(len(sis_result))\n",
    "# print(sis_result)\n",
    "                            \n",
    "# Add k_series_result back to member\n",
    "\n",
    "digitalhub_sub_collection_recall_df['members'] = digitalhub_sub_collection_recall_df['members'].astype('object')\n",
    "digitalhub_sub_collection_recall_df.at[44,'members'] = diaw_result\n",
    "\n",
    "\n",
    "####################################################################################################################\n",
    "### Add private files and one sub_collection to Center for Biomedical Informatics --> Biomedical_data_science_day###\n",
    "####################################################################################################################\n",
    "\n",
    "\n",
    "add_to_series_path_0 = r\"data\\sub_collection\\private_centerforbiomedical_biomedicalday_heartrate.txt\"\n",
    "add_to_series_path_0_0 = r\"data\\sub_collection\\private_centerforbiomedical_biomedicalday_overviewofcausal.txt\"\n",
    "add_to_series_path_0_1 = r\"data\\sub_collection\\private_centerforbiomedical_biomedicalday_predictingsevere.txt\"\n",
    "add_to_series_path_0_2 = r\"data\\sub_collection\\private_centerforbiomedical_biomedicalday_feinberg2016.txt\"\n",
    "add_to_series_path_0_3 = r\"data\\sub_collection\\private_centerforbiomedical_chicagobiomedicaljam_chicagobiomedicaljam2016.txt\" ## subcollection\n",
    "\n",
    "biomed_private_path_list = [add_to_series_path_0,\n",
    "                            add_to_series_path_0_0,\n",
    "                            add_to_series_path_0_1,\n",
    "                            add_to_series_path_0_2\n",
    "                           ]\n",
    "\n",
    "biomed_private_list = [] \n",
    "\n",
    "for path in biomed_private_path_list: \n",
    "    with open(path, 'r', encoding= 'utf8') as f:\n",
    "        s = f.read()    \n",
    "        result = json.loads(s)   # try to parse...\n",
    "        biomed_private_list.append(result)\n",
    "\n",
    "\n",
    "## Create a list from the existing members column for the collection\n",
    "current_series_0 = digitalhub_sub_collection_recall_df.loc[digitalhub_sub_collection_recall_df['Id'] == 'ab570598-e497-4c81-9351-1aa316252682','members']\n",
    "# print(current_series_0.item()[0])\n",
    "\n",
    "##Add items from biomed_private_list list to current_series\n",
    "biomed_result = []\n",
    "biomed_result = current_series_0.item() + [x for x in biomed_private_list if x not in current_series_0.items()]\n",
    "print(len(biomed_result))\n",
    "# print(biomed_result)\n",
    "                            \n",
    "# Add biomed_result back to member\n",
    "\n",
    "digitalhub_sub_collection_recall_df['members'] = digitalhub_sub_collection_recall_df['members'].astype('object')\n",
    "digitalhub_sub_collection_recall_df.at[5,'members'] = biomed_result   \n",
    "\n",
    "\n",
    "##########################################################################################################################################\n",
    "### Add private files to Galter Library Audio-Visual Archive --> Northwestern University Medical School, Class of 1952: an oral history###\n",
    "##########################################################################################################################################\n",
    "\n",
    "\n",
    "add_to_series_path_1_0_0 = r\"data\\sub_collection\\private_av_archive_oral_histories_interviews_with_Alfred_F_Anderegg.txt\"\n",
    "add_to_series_path_1_0_1 = r\"data\\sub_collection\\private_av_archive_oral_histories_interviews_with_Maurice_Gore.txt\"\n",
    "add_to_series_path_1_0_2 = r\"data\\sub_collection\\private_av_archive_oral_histories_sample_of.txt\"\n",
    "\n",
    "\n",
    "oral_private_path_list = [add_to_series_path_1_0_0,\n",
    "                            add_to_series_path_1_0_1,\n",
    "                            add_to_series_path_1_0_2\n",
    "                           ]\n",
    "\n",
    "oral_private_list = [] \n",
    "\n",
    "for path in oral_private_path_list: \n",
    "    with open(path, 'r', encoding= 'utf8') as f:\n",
    "        s = f.read()    \n",
    "        result = json.loads(s)   # try to parse...\n",
    "        oral_private_list.append(result)\n",
    "\n",
    "\n",
    "## Create a list from the existing members column for the collection\n",
    "current_series_1_0_0 = digitalhub_sub_collection_recall_df.loc[digitalhub_sub_collection_recall_df['Id'] == 'cece380d-4dee-4e4e-aa97-28cb1d4f6b19','members']\n",
    "# print(current_series_1_0_0.item()[0])\n",
    "\n",
    "##Add items from private_list to current_series\n",
    "oral_result = current_series_1_0_0.item() + [x for x in oral_private_list if x not in current_series_1_0_0.items()]\n",
    "print(len(oral_result))\n",
    "# print(oral_result)\n",
    "                            \n",
    "# Add result back to member\n",
    "\n",
    "digitalhub_sub_collection_recall_df['members'] = digitalhub_sub_collection_recall_df['members'].astype('object')\n",
    "digitalhub_sub_collection_recall_df.at[54,'members'] = oral_result   \n",
    "\n",
    "#############################################################################################################################\n",
    "### Add private files to History of Feinberg School of Medicine --> Special Collections- Art (known as Portraits in Prism ###\n",
    "#############################################################################################################################\n",
    "\n",
    "\n",
    "add_to_series_path_2_0_0 = r\"data\\sub_collection\\private_feinberghistory_portraits_louiskeith.txt\"\n",
    "\n",
    "\n",
    "portrait_private_path_list = [add_to_series_path_2_0_0]\n",
    "\n",
    "portrait_private_list = [] \n",
    "\n",
    "for path in portrait_private_path_list: \n",
    "    with open(path, 'r', encoding= 'utf8') as f:\n",
    "        s = f.read()    \n",
    "        result = json.loads(s)   # try to parse...\n",
    "        portrait_private_list.append(result)\n",
    "\n",
    "\n",
    "## Create a list from the existing members column for the collection\n",
    "current_series_2_0_0 = digitalhub_sub_collection_recall_df.loc[digitalhub_sub_collection_recall_df['Id'] == '2f75r807r','members']\n",
    "# print(current_series_2_0_0.item()[0])\n",
    "\n",
    "##Add items from private_list to current_series\n",
    "portrait_result = current_series_2_0_0.item() + [x for x in portrait_private_list if x not in current_series_2_0_0.items()]\n",
    "print(len(portrait_result))\n",
    "# print(portrait_result)\n",
    "                            \n",
    "# Add result back to member\n",
    "\n",
    "digitalhub_sub_collection_recall_df['members'] = digitalhub_sub_collection_recall_df['members'].astype('object')\n",
    "digitalhub_sub_collection_recall_df.at[55,'members'] = portrait_result\n",
    "\n",
    "#############################################################################################\n",
    "### Add private files to History of Feinberg School of Medicine --> Photos from the vault ###\n",
    "#############################################################################################\n",
    "\n",
    "\n",
    "add_to_series_path_3_0_0 = r\"data\\sub_collection\\private_feinberghistory_vault_alumnilibrary.txt\"\n",
    "\n",
    "\n",
    "vault_private_path_list = [add_to_series_path_3_0_0]\n",
    "\n",
    "vault_private_list = [] \n",
    "\n",
    "for path in vault_private_path_list: \n",
    "    with open(path, 'r', encoding= 'utf8') as f:\n",
    "        s = f.read()    \n",
    "        result = json.loads(s)   # try to parse...\n",
    "        vault_private_list.append(result)\n",
    "\n",
    "\n",
    "## Create a list from the existing members column for the collection\n",
    "current_series_3_0_0 = digitalhub_sub_collection_recall_df.loc[digitalhub_sub_collection_recall_df['Id'] == '5712m6524','members']\n",
    "# print(current_series_3_0_0.item()[0])\n",
    "\n",
    "##Add items from private_list to current_series\n",
    "vault_result = current_series_3_0_0.item() + [x for x in vault_private_list if x not in current_series_3_0_0.items()]\n",
    "print(len(vault_result))\n",
    "# print(vault_result)\n",
    "                            \n",
    "# Add result back to member\n",
    "\n",
    "digitalhub_sub_collection_recall_df['members'] = digitalhub_sub_collection_recall_df['members'].astype('object')\n",
    "digitalhub_sub_collection_recall_df.at[56,'members'] = vault_result\n",
    "\n",
    "\n",
    "###########################################################################################################\n",
    "### Add private files to Researchers' Collections --> Expression of receptors for plasminogen activators###\n",
    "###########################################################################################################\n",
    "\n",
    "\n",
    "add_to_series_path_4_0_0 = r\"data\\sub_collection\\private_researcher_expressionofreceptors_changesinblood.txt\"\n",
    "add_to_series_path_4_1_0 = r\"data\\sub_collection\\private_researcher_expressionofreceptors_particulate.txt\"\n",
    "add_to_series_path_4_2_0 = r\"data\\sub_collection\\private_researcher_expressionofreceptors_theapparent.txt\"\n",
    "add_to_series_path_4_3_0 = r\"data\\sub_collection\\private_researcher_expressionofreceptors_theroleof.txt\"\n",
    "\n",
    "\n",
    "express_private_path_list = [add_to_series_path_4_0_0,\n",
    "                             add_to_series_path_4_1_0,\n",
    "                             add_to_series_path_4_2_0,\n",
    "                             add_to_series_path_4_3_0]\n",
    "\n",
    "express_private_list = [] \n",
    "\n",
    "for path in express_private_path_list: \n",
    "    with open(path, 'r', encoding= 'utf8') as f:\n",
    "        s = f.read()    \n",
    "        result = json.loads(s)   # try to parse...\n",
    "        express_private_list.append(result)\n",
    "\n",
    "\n",
    "## Create a list from the existing members column for the collection\n",
    "current_series_4_0_0 = digitalhub_sub_collection_recall_df.loc[digitalhub_sub_collection_recall_df['Id'] == 'fj236212d','members']\n",
    "# print(current_series_4_0_0.item()[0])\n",
    "\n",
    "##Add items from private_list to current_series\n",
    "express_result = current_series_4_0_0.item() + [x for x in express_private_list if x not in current_series_4_0_0.items()]\n",
    "print(\"this is len\",len(express_result))\n",
    "print(express_result)\n",
    "                            \n",
    "# Add result back to member\n",
    "\n",
    "digitalhub_sub_collection_recall_df['members'] = digitalhub_sub_collection_recall_df['members'].astype('object')\n",
    "digitalhub_sub_collection_recall_df.at[76,'members'] = express_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2d228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspect the \"members\" column and create a list of member IDs\n",
    "\n",
    "row_sub_collection_member_list = []\n",
    "column_sub_collection_member_dict ={}\n",
    "count_sub_collection_member_dict = {}\n",
    "\n",
    "\n",
    "for k, v in digitalhub_sub_collection_recall_df[\"members\"].items():\n",
    "    for value in v: \n",
    "        member = value[\"Id\"]\n",
    "        row_sub_collection_member_list.append(member)\n",
    "        count_sub_collection_member_dict[k] = len(row_sub_collection_member_list)\n",
    "    column_sub_collection_member_dict[k] = row_sub_collection_member_list\n",
    "    row_sub_collection_member_list =[]\n",
    "   \n",
    "## Append the column member dictionary to the digitalhub_sub_collection_recall_df dataframe\n",
    "\n",
    "digitalhub_sub_collection_recall_df['Member_List'] = digitalhub_sub_collection_recall_df.index.map(column_sub_collection_member_dict)\n",
    "digitalhub_sub_collection_recall_df['Member_List_Count'] = digitalhub_sub_collection_recall_df.index.map(count_sub_collection_member_dict)\n",
    "# digitalhub_sub_collection_recall_df.head()\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45993e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export file to excel, without the Pandas index, but with the header\n",
    "\n",
    "digitalhub_sub_collection_recall_df.to_excel(\"outputs/digitalhub_sub_collection_recall_df.xlsx\", index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1b6207",
   "metadata": {},
   "source": [
    "##### Split Recall Sub_Collection into Members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e06a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a dataframe for each members row and concatenate all of these into one member_df\n",
    "\n",
    "sub_collection_members_dfs_list = []\n",
    "\n",
    "for k, v in digitalhub_sub_collection_recall_df[\"members\"].items():\n",
    "#     print(\"this is k: \", k)\n",
    "#     print(\"this is v: \", v)\n",
    "    sub_collection_member_df = pd.json_normalize(v)\n",
    "    sub_collection_member_df['sub_collection_rowid'] = k\n",
    "    sub_collection_members_dfs_list.append(sub_collection_member_df)\n",
    "\n",
    "digitalhub_sub_collection_members_df = pd.concat(sub_collection_members_dfs_list, sort=False).reset_index(drop='index')\n",
    "# digitalhub_sub_collection_members_df.head()\n",
    "\n",
    "## Resource\n",
    "## https://stackoverflow.com/questions/62816027/convert-pandas-json-column-to-multiple-rows\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006cdc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add Column to digitalhub_community_df to indicate that these results are a collection\n",
    "\n",
    "digitalhub_sub_collection_members_df['Level Type'] = np.where(digitalhub_sub_collection_members_df['DOI'].isnull(),\"Sub_Sub_Collection\", \"Record\" )\n",
    "digitalhub_sub_collection_members_df['Level Number'] = np.where(digitalhub_sub_collection_members_df['DOI'].isnull(),\"3\", \"6\" )\n",
    "digitalhub_sub_collection_members_df['Level Number'] = digitalhub_sub_collection_members_df['Level Number'].apply(int)\n",
    "# digitalhub_sub_collection_members_df.head()\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea416ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export file to excel with the header\n",
    "\n",
    "digitalhub_sub_collection_members_df.to_excel(\"outputs/digitalhub_sub_collection_members_df.xlsx\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1b2b17",
   "metadata": {},
   "source": [
    "##### Concatenate Recall Sub_Collection with Members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c1df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate the DigitalHub Sub_Collection_Recall Dataframe using the 'rowid' to the DigitalHub Sub_Collection Members Dataframe using the 'rowid'\n",
    "\n",
    "digitalhub_sub_col_members_df = pd.concat([digitalhub_sub_collection_recall_df, digitalhub_sub_collection_members_df], axis=0).sort_values(by=['sub_collection_rowid'])\n",
    "# digitalhub_sub_col_members_df.head()\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38481700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8d4b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort the dataframe by sub_collection_rowid and Level Number to prepare for group by and forward fill of Sub_Collection_ID\n",
    "\n",
    "digitalhub_sub_col_members_df.sort_values(by = ['sub_collection_rowid','Level Number'], ascending = [True, True], inplace=True)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5553f5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Groupby Sub_Collection_rowid and fill forward the Sub_Collection_ID into members of sub_collections (i.e. sub_sub_collections and records)\n",
    "\n",
    "digitalhub_sub_col_members_df.update(digitalhub_sub_col_members_df.groupby(['sub_collection_rowid'])['Sub_Collection_ID'].ffill())\n",
    "\n",
    "## Resources\n",
    "## https://stackoverflow.com/questions/64795941/how-do-i-forward-fill-nas-with-condition-of-2-other-cells-being-equal-in-pandas\n",
    "## https://stackoverflow.com/questions/27012151/forward-fill-specific-columns-in-pandas-dataframe\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2712bf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a column for Sub_Sub_Collection_ID to hold the Id from columns with Level Type as \"Sub_Sub_Collection\"\n",
    "\n",
    "digitalhub_sub_col_members_df['Sub_Sub_Collection_ID'] = np.where(digitalhub_sub_col_members_df['Level Type'] == 'Sub_Sub_Collection',digitalhub_sub_col_members_df['Id'], np.nan)\n",
    "\n",
    "## Resources\n",
    "## https://stackoverflow.com/questions/67043249/how-to-use-np-where-in-creating-new-column-using-previous-rows\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9a4183",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export file to excel, without the Pandas index, but with the header\n",
    "\n",
    "digitalhub_sub_col_members_df.to_excel(\"outputs/digitalhub_sub_col_members_df.xlsx\", index=False, header=True)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b4babb",
   "metadata": {},
   "source": [
    "##### Concatenate Sub_Collection with Community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ebbe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate the DigitalHub digitalhub_comm_col_df Dataframe using the 'Id' to the DigitalHub digitalhub_sub_col_members_df Dataframe using the 'Id'\n",
    "\n",
    "#digitalhub_comm_col_df\n",
    "#digitalhub_sub_col_members_df\n",
    "\n",
    "digitalhub_sub_col_sub_col_df = pd.concat([digitalhub_comm_col_df, digitalhub_sub_col_members_df], axis=0).sort_values(by=['Community_ID', 'Sub_Collection_ID'])\n",
    "# digitalhub_sub_col_sub_col_df.head()\n",
    "\n",
    "## Checked: No problems\n",
    "## Note: Creates duplicate rows for \"Sub_Collection_ID\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6602835",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort the dataframe by Id and Level Number to get ready to groupby ID and remove duplicate Sub_Collections from the concatenate\n",
    "\n",
    "digitalhub_sub_col_sub_col_df.sort_values(by = ['Id','Level Number'], ascending = [True, True], inplace=True)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a6d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the duplicate Sub_Collections based on their Id and take the first non-null data\n",
    "\n",
    "digitalhub_sub_col_sub_col_df = digitalhub_sub_col_sub_col_df.groupby(['Id'], as_index=False).first().reset_index()\n",
    "\n",
    "## Resources: \n",
    "## https://stackoverflow.com/questions/64795941/how-do-i-forward-fill-nas-with-condition-of-2-other-cells-being-equal-in-pandas\n",
    "## https://www.pauldesalvo.com/how-to-apply-a-forward-fill-ffill-to-groups-in-pandas/\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbdeac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort the dataframe by Sub_Collection_ID and then Level Number to get ready to fill Community IDs into connected Sub_Collections\n",
    "\n",
    "digitalhub_sub_col_sub_col_df.sort_values(by = ['Sub_Collection_ID','Level Number'], ascending = [True, True], inplace=True)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b4050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill foward the Community_ID into Records based on their Sub_Collection_IDs\n",
    "\n",
    "digitalhub_sub_col_sub_col_df.update(digitalhub_sub_col_sub_col_df.groupby(['Sub_Collection_ID'])['Community_ID'].ffill())\n",
    "\n",
    "## Other options\n",
    "##digitalhub_sub_col_sub_col_df['Community_ID'] = digitalhub_sub_col_sub_col_df.groupby(['Sub_Collection_ID'])['Community_ID'].fillna(method='ffill')\n",
    "##digitalhub_sub_col_sub_col_df['Community_ID'] = digitalhub_sub_col_sub_col_df.groupby(['Sub_Collection_ID'])['Community_ID'].transform(lambda x: x.ffill())\n",
    "##digitalhub_sub_col_sub_col_df['Community_ID'] = digitalhub_sub_col_sub_col_df.groupby(['Sub_Collection_ID'])['Community_ID'].fillna(method='ffill')\n",
    "\n",
    "## Resources\n",
    "## https://stackoverflow.com/questions/64795941/how-do-i-forward-fill-nas-with-condition-of-2-other-cells-being-equal-in-pandas\n",
    "## https://stackoverflow.com/questions/58181262/groupby-with-ffill-deletes-group-and-does-not-put-group-in-index\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62079974",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export file to excel with the header\n",
    "\n",
    "digitalhub_sub_col_sub_col_df.to_excel(\"outputs/digitalhub_sub_col_sub_col_df.xlsx\",  header=True)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11c02c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT NEED\n",
    "## Because of groupby issue from above, re-add the community id for communities that lost theirs\n",
    "\n",
    "## Sort the dataframe by rowid and Level Number\n",
    "# digitalhub_sub_col_sub_col_df.sort_values(by = ['community_rowid','Level Number'], ascending = [True, True], inplace=True)\n",
    "\n",
    "# ## Create a column for Sub_Collection ID\n",
    "# digitalhub_sub_col_sub_col_df['Community_ID'] = np.where(digitalhub_sub_col_sub_col_df['Level Type'] == 'Community',digitalhub_sub_col_sub_col_df['Id'], np.nan)\n",
    "\n",
    "# ## https://stackoverflow.com/questions/67043249/how-to-use-np-where-in-creating-new-column-using-previous-rows\n",
    "\n",
    "# # ## Fill forward the Community ID into subcollections and records\n",
    "# digitalhub_sub_col_sub_col_df['Community_ID'] = digitalhub_sub_col_sub_col_df.groupby(['community_rowid'])['Community_ID'].ffill()\n",
    "\n",
    "# ## https://stackoverflow.com/questions/64795941/how-do-i-forward-fill-nas-with-condition-of-2-other-cells-being-equal-in-pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae041936",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT NEED\n",
    "## Export file to excel, without the Pandas index, but with the header\n",
    "\n",
    "# digitalhub_sub_col_sub_col_df.to_excel(\"outputs/digitalhub_sub_col_sub_col_df.xlsx\",  header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60bc43a",
   "metadata": {},
   "source": [
    "##### Recall Sub_Sub_Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f710f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract a the Series for sub_sub_collection \"dh_id\" and transform into a list\n",
    "\n",
    "digitalhub_sub_sub_collection_series = digitalhub_sub_col_sub_col_df[digitalhub_sub_col_sub_col_df[\"Level Type\"] == \"Sub_Sub_Collection\"]['Id']\n",
    "digitalhub_sub_sub_collection_list = digitalhub_sub_sub_collection_series.tolist()\n",
    "\n",
    "print(digitalhub_sub_sub_collection_list)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29db6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop through list of DigitalHub Sub_Sub_Collections and use the urllib.request to get the json data\n",
    "## test_list = ['2cc92425-b656-47ea-a3b4-825405ee6088', 'a86e1412-d72c-4cae-b8ca-16fd834cb128','fc389d13-2430-409b-82fd-a4b26613d350']\n",
    "\n",
    "multi_digitalhub_sub_sub_collection_list = []\n",
    "digitalhub_sub_sub_collection_problem_list = []\n",
    "\n",
    "for item in digitalhub_sub_sub_collection_list:\n",
    "    try:\n",
    "\n",
    "        with urllib.request.urlopen(f\"https://digitalhub.northwestern.edu/collections/{item}.json\" ) as url:\n",
    "            single_digitalhub_sub_sub_collection_dict = json.loads(url.read().decode())\n",
    "            multi_digitalhub_sub_sub_collection_list.append(single_digitalhub_sub_sub_collection_dict)\n",
    "            print(item)\n",
    "        time.sleep(1)\n",
    "       \n",
    "\n",
    "    except urllib.error.HTTPError as http_err:\n",
    "        print(item)\n",
    "        digitalhub_sub_sub_collection_problem_list.append(item)\n",
    "        print(f'HTTP error occurred: {http_err}')  # Python 3.6\n",
    "        \n",
    "\n",
    "    except urllib.error.URLError as url_err:\n",
    "        print(item)\n",
    "        digitalhub_sub_sub_collection_problem_list.append(item)\n",
    "        print(f'URL error occurred: {url_err}. ', 'Exiting the loop!')  # Python 3.6\n",
    "       \n",
    "\n",
    "    except json.JSONDecodeError as json_err:\n",
    "        print(item)\n",
    "        digitalhub_sub_sub_collection_problem_list.append(item)\n",
    "        print(f'JSON Decode error occurred: {json_err}. ', 'Poorly formed JSON.')  # Python 3.6\n",
    "       \n",
    "        \n",
    "    except Exception as err:\n",
    "        print(item)\n",
    "        digitalhub_sub_sub_collection_problem_list.append(item)\n",
    "        print(f'Other error occurred: {err}. ')  # Python 3.6\n",
    "        \n",
    "        \n",
    "       \n",
    "    else:\n",
    "        print('Success!')\n",
    "\n",
    "\n",
    "\n",
    "## Resources\n",
    "## https://docs.python.org/3/library/urllib.request.html\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df97cd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspect the results of the URL Query for DigitalHub Collections that will become communities in Prism\n",
    "\n",
    "# print(multi_digitalhub_sub_sub_collection_list)\n",
    "print(len(digitalhub_sub_sub_collection_problem_list))\n",
    "print(digitalhub_sub_sub_collection_problem_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9cdfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a dataframe from DigitalHub json for DigitalHub Sub_Sub_Collections\n",
    "\n",
    "digitalhub_sub_sub_collection_recall_df = pd.DataFrame.from_dict(json_normalize(multi_digitalhub_sub_sub_collection_list, max_level=1))\n",
    "digitalhub_sub_sub_collection_recall_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91565868",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Upload .txt files of the problem Sub_Sub_Collection json metadata\n",
    "\n",
    "## 1. Problem with:8b34974a-1cef-402d-8a57-c04c1f015fa9\n",
    "## child-1-of-template-0 (10-04-19)\n",
    "\n",
    "## 2. Problem with: af7512ff-addc-457c-b2c2-22f49b3aaab0\n",
    "## child-0-of-template-0 (10-04-19)\n",
    "\n",
    "## 3. PRoblem with: eaf6729a-34d6-4dec-ae66-c339f14fe1ea\n",
    "## child-2-of-template-0 (10-04-19)\n",
    "\n",
    "## 4.Problem with: 906b9f6e-a70e-4821-aee0-9a038ec909d5\n",
    "## child-1-of-template-1 (10-04-19)\n",
    "\n",
    "## 5. Problem with:a4ba4155-9cd8-43eb-b4a7-865e50b61dc0\n",
    "## child-0-of-template-1 (10-04-19)\n",
    "\n",
    "## 6. Problem with:c2b21560-15fb-4c7d-a7ca-2ecee215a647\n",
    "## child-2-of-template-1 (10-04-19)\n",
    "\n",
    "## 7. Problem with: 49945521-3b35-4efd-9e77-e909900f1604\n",
    "R03_path = r\"data\\sub_sub_collection\\R03.txt\"\n",
    "\n",
    "## 8. Problem with: 6a9690f5-664a-4654-a5ca-c1c1ca99db9b \n",
    "R01_path = r\"data\\sub_sub_collection\\R01.txt\"\n",
    "\n",
    "## 9. Problem with: af85d02b-4b6c-48db-8cac-b82f4075e1f0 \n",
    "R21_path = r\"data\\sub_sub_collection\\R21.txt\"\n",
    "\n",
    "## 10. Problem with: 7d40546b-cad0-4838-b289-947b5187c02a \n",
    "biosketches_path = r\"data\\sub_sub_collection\\biosketches.txt\"\n",
    "\n",
    "## 11. Problem with: cb52ca3c-f967-41b1-886d-60f5611706ac\n",
    "summary_statements_path = r\"data\\sub_sub_collection\\summary_statements.txt\"\n",
    "\n",
    "## 12. Problem with: c6f1d0a2-9bc2-424f-aebe-1ea6beed176d\n",
    "## is a file, but was never given a DOI. Tunc-Ozcan_K99R00_7.22.2021.pdf \n",
    "\n",
    "## 13. Problem with:\n",
    "health_and_welfare_path = r\"data\\sub_sub_collection\\health_and_welfare.txt\"\n",
    "\n",
    "## 14. Problem with:\n",
    "fight_for_life_path = r\"data\\sub_sub_collection\\fight_for_life.txt\"\n",
    "\n",
    "## 15. Problem with:\n",
    "unlabeled_1_path = r\"data\\sub_sub_collection\\unlabeled_1.txt\"\n",
    "\n",
    "## 16. Problem with:\n",
    "unlabeled_2_path = r\"data\\sub_sub_collection\\unlabeled_2.txt\"\n",
    "\n",
    "## 17. Problem with:\n",
    "a_little_culture_path =  r\"data\\sub_sub_collection\\a_little_culture.txt\"\n",
    "\n",
    "## 18. Problem with:\n",
    "bachelors_degree_1_path =  r\"data\\sub_sub_collection\\bachelors_degree_1.txt\"\n",
    "\n",
    "## 19. Problem with:\n",
    "bachelors_degree_2_path = r\"data\\sub_sub_collection\\bachelors_degree_2.txt\"\n",
    "\n",
    "\n",
    "problem_sub_sub_dict_list = []\n",
    "\n",
    "path_sub_sub_list = [biosketches_path, \n",
    "                     R01_path, \n",
    "                     R03_path, \n",
    "                     R21_path, \n",
    "                     summary_statements_path,\n",
    "                     health_and_welfare_path,\n",
    "                     fight_for_life_path,\n",
    "                     unlabeled_1_path,\n",
    "                     unlabeled_2_path,\n",
    "                     a_little_culture_path,\n",
    "                     bachelors_degree_1_path,\n",
    "                     bachelors_degree_2_path]\n",
    "\n",
    "for path in path_sub_sub_list: \n",
    "#     print(path)\n",
    "    with open(path, 'r', encoding= 'utf8') as f:\n",
    "        s = f.read()\n",
    "#         problem_sub_sub_dict = json.loads(data)\n",
    "#         problem_sub_sub_dict_list.append(problem_sub_dict)\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                result = json.loads(s)   # try to parse...\n",
    "                break                    # parsing worked -> exit loop\n",
    "            except Exception as e:\n",
    "                # \"Expecting , delimiter: line 34 column 54 (char 1158)\"\n",
    "                # position of unexpected character after '\"'\n",
    "                unexp = int(re.findall(r'\\(char (\\d+)\\)', str(e))[0])\n",
    "                # position of unescaped '\"' before that\n",
    "                unesc = s.rfind(r'\"', 0, unexp)\n",
    "                s = s[:unesc] + r'\\\"' + s[unesc+1:]\n",
    "                # position of correspondig closing '\"' (+2 for inserted '\\')\n",
    "                closg = s.find(r'\"', unesc + 2)\n",
    "                s = s[:closg] + r'\\\"' + s[closg+1:]\n",
    "#         print(result)\n",
    "        problem_sub_sub_dict_list.append(result)\n",
    "\n",
    "\n",
    "\n",
    "## https://stackoverflow.com/questions/16573332/jsondecodeerror-expecting-value-line-1-column-1-char-0\n",
    "## https://stackoverflow.com/questions/18514910/how-do-i-automatically-fix-an-invalid-json-string\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b373b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_sub_sub_df = pd.DataFrame.from_dict(json_normalize(problem_sub_sub_dict_list, max_level=1))\n",
    "problem_sub_sub_df.head()\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583bc759",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate the DigitalHub Community Dataframe to the problem_df\n",
    "\n",
    "digitalhub_sub_sub_collection_recall_df= pd.concat([digitalhub_sub_sub_collection_recall_df, problem_sub_sub_df], axis=0)\n",
    "digitalhub_sub_sub_collection_recall_df.reset_index(inplace=True, drop=True) \n",
    "digitalhub_sub_sub_collection_recall_df.head(10)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf9f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add Column to digitalhub_sub_sub_collection_df to indicate that these results are a sub_sub_collection\n",
    "digitalhub_sub_sub_collection_recall_df[\"Level Type\"] = \"Sub_Sub_Collection\"\n",
    "digitalhub_sub_sub_collection_recall_df[\"Level Number\"] = \"3\"\n",
    "digitalhub_sub_sub_collection_recall_df['Level Number'] = digitalhub_sub_sub_collection_recall_df['Level Number'].apply(int)\n",
    "\n",
    "## Create a column from the index\n",
    "digitalhub_sub_sub_collection_recall_df['sub_sub_collection_rowid'] = digitalhub_sub_sub_collection_recall_df.index\n",
    "\n",
    "## Create a new column called Sub_Collection_ID\n",
    "digitalhub_sub_sub_collection_recall_df['Sub_Sub_Collection_ID'] = digitalhub_sub_sub_collection_recall_df['Id']\n",
    "\n",
    "## Checked: No problems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8805d8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "##### Add records to sub_sub_collection || Add sub-sub_sub_collections to sub_sub_collection ####\n",
    "##################################################################################################\n",
    "\n",
    "#################################################################################\n",
    "## Add private files to 12th General Hospital --> Mason --> General Reports ####\n",
    "################################################################################\n",
    "\n",
    "add_to_series_path_8 = r\"data\\sub_sub_collection\\private_12_general_Mason_12_Gen_Reports_Final_Report.txt\"\n",
    "\n",
    "gen_reports_private_path_list = [add_to_series_path_8]\n",
    "\n",
    "gen_reports_private_list = [] \n",
    "\n",
    "for path in gen_reports_private_path_list: \n",
    "    with open(path, 'r', encoding= 'utf8') as f:\n",
    "        s = f.read()    \n",
    "        result = json.loads(s)   # try to parse...\n",
    "        gen_reports_private_list.append(result)\n",
    "\n",
    "\n",
    "## Create a list from the existing members column for the collection\n",
    "current_list_8=[]\n",
    "current_series_8 = digitalhub_sub_sub_collection_recall_df.loc[digitalhub_sub_sub_collection_recall_df['Id'] == '1a3c738a-ba69-4275-98b0-fc77939d5b93','members']\n",
    "#print(current_series_8.item()[0])\n",
    "\n",
    "##Add items from gen_reports_private_list to current_series\n",
    "gen_reports_result = []\n",
    "gen_reports_result = current_series_8.item() + [x for x in gen_reports_private_list if x not in current_series_8.items()]\n",
    "print(len(gen_reports_result))\n",
    "# print(gen_reports_result)\n",
    "                            \n",
    "# Add k_series_result back to member\n",
    "\n",
    "digitalhub_sub_sub_collection_recall_df['members'] = digitalhub_sub_sub_collection_recall_df['members'].astype('object')\n",
    "digitalhub_sub_sub_collection_recall_df.at[11,'members'] = gen_reports_result \n",
    "\n",
    "\n",
    "############################################################################\n",
    "## Add private files to 12th General Hospital --> Mason --> Photographs ####\n",
    "############################################################################\n",
    "\n",
    "add_to_series_path_9 = r\"data\\sub_sub_collection\\private_12_general_Mason_photographs_miscellaneous_14.txt\"\n",
    "add_to_series_path_10 = r\"data\\sub_sub_collection\\private_12_general_Mason_photographs_rome_034.txt\"\n",
    "\n",
    "photographs_private_path_list = [add_to_series_path_9,\n",
    "                                 add_to_series_path_10]\n",
    "\n",
    "photographs_private_list = [] \n",
    "\n",
    "for path in photographs_private_path_list: \n",
    "    with open(path, 'r', encoding= 'utf8') as f:\n",
    "        s = f.read()    \n",
    "        result = json.loads(s)   # try to parse...\n",
    "        photographs_private_list.append(result)\n",
    "\n",
    "\n",
    "## Create a list from the existing members column for the collection\n",
    "current_list_10=[]\n",
    "current_series_10 = digitalhub_sub_sub_collection_recall_df.loc[digitalhub_sub_sub_collection_recall_df['Id'] == '19e0660b-7dd3-480b-b3ec-b57a12f34014','members']\n",
    "#print(current_series_10.item()[0])\n",
    "\n",
    "##Add items from photographs_private_list to current_series\n",
    "photographs_result = []\n",
    "photographs_result = current_series_10.item() + [x for x in photographs_private_list if x not in current_series_10.items()]\n",
    "print(len(photographs_result))\n",
    "# print(photographs_result)\n",
    "                            \n",
    "# Add photographs back to member\n",
    "\n",
    "digitalhub_sub_sub_collection_recall_df['members'] = digitalhub_sub_sub_collection_recall_df['members'].astype('object')\n",
    "digitalhub_sub_sub_collection_recall_df.at[10,'members'] = photographs_result \n",
    "\n",
    "#############################################################################################################################################################################################################\n",
    "### Add private files to Medical Subject Headings-Library of Congress Subject Headings Mapping Data --> Library of Congress Subject Headings Authority Records with Medical Subject Headings mapping data###\n",
    "############################################################################################################################################################################################################\n",
    "\n",
    "\n",
    "add_to_series_path_8_0 = r\"data\\sub_sub_collection\\private_mesh_lcsh_lcsh2018.txt\"\n",
    "add_to_series_path_8_1 = r\"data\\sub_sub_collection\\private_mesh_lcsh_lcsh2018_2.txt\"\n",
    "\n",
    "\n",
    "lcsh_private_path_list = [add_to_series_path_8_0,\n",
    "                            add_to_series_path_8_1]\n",
    "\n",
    "lcsh_private_list = [] \n",
    "\n",
    "for path in lcsh_private_path_list: \n",
    "    with open(path, 'r', encoding= 'utf8') as f:\n",
    "        s = f.read()    \n",
    "        result = json.loads(s)   # try to parse...\n",
    "        lcsh_private_list.append(result)\n",
    "\n",
    "\n",
    "## Create a list from the existing members column for the collection\n",
    "current_series_8_0 = digitalhub_sub_sub_collection_recall_df.loc[digitalhub_sub_sub_collection_recall_df['Id'] == '3e59c5b9-bbbf-4f49-946f-e08ef9b10d9f','members']\n",
    "# print(current_series_8_0.item()[0])\n",
    "\n",
    "##Add items from private_list list to current_series\n",
    "lcsh_result = []\n",
    "lcsh_result = current_series_8_0.item() + [x for x in lcsh_private_list if x not in current_series_8_0.items()]\n",
    "print(len(lcsh_result))\n",
    "# print(lcsh_result)\n",
    "                            \n",
    "# Add result back to member\n",
    "\n",
    "digitalhub_sub_sub_collection_recall_df['members'] = digitalhub_sub_sub_collection_recall_df['members'].astype('object')\n",
    "digitalhub_sub_sub_collection_recall_df.at[0,'members'] = lcsh_result \n",
    "\n",
    "#############################################################################################################################################################################################################\n",
    "### Add private files to Medical Subject Headings-Library of Congress Subject Headings Mapping Data --> Medical Subject Headings Authority Records with Library of Congress Subject Headings mapping data###\n",
    "############################################################################################################################################################################################################\n",
    "\n",
    "\n",
    "add_to_series_path_9_0 = r\"data\\sub_sub_collection\\private_mesh_mesh_mesh2018.txt\"\n",
    "add_to_series_path_9_1 = r\"data\\sub_sub_collection\\private_mesh_mesh_mesh2018_2.txt\"\n",
    "\n",
    "\n",
    "mesh_private_path_list = [add_to_series_path_9_0,\n",
    "                            add_to_series_path_9_1]\n",
    "\n",
    "mesh_private_list = [] \n",
    "\n",
    "for path in mesh_private_path_list: \n",
    "    with open(path, 'r', encoding= 'utf8') as f:\n",
    "        s = f.read()    \n",
    "        result = json.loads(s)   # try to parse...\n",
    "        mesh_private_list.append(result)\n",
    "\n",
    "\n",
    "## Create a list from the existing members column for the collection\n",
    "current_series_9_0 = digitalhub_sub_sub_collection_recall_df.loc[digitalhub_sub_sub_collection_recall_df['Id'] == '4b7f6a77-9cf4-4deb-b9aa-f3f49391bcc8','members']\n",
    "# print(current_series_9_0.item()[0])\n",
    "\n",
    "##Add items from private_list list to current_series\n",
    "mesh_result = []\n",
    "mesh_result = current_series_9_0.item() + [x for x in mesh_private_list if x not in current_series_9_0.items()]\n",
    "print(len(mesh_result))\n",
    "#print(mesh_result)\n",
    "                            \n",
    "# Add result back to member\n",
    "\n",
    "digitalhub_sub_sub_collection_recall_df['members'] = digitalhub_sub_sub_collection_recall_df['members'].astype('object')\n",
    "digitalhub_sub_sub_collection_recall_df.at[1,'members'] = mesh_result  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee8fcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspect the \"members\" column and create a list of member IDs\n",
    "\n",
    "row_sub_sub_collection_member_list = []\n",
    "column_sub_sub_collection_member_dict ={}\n",
    "count_sub_sub_collection_member_dict = {}\n",
    "\n",
    "for k, v in digitalhub_sub_sub_collection_recall_df[\"members\"].items():\n",
    "    for value in v: \n",
    "        member = value[\"Id\"]\n",
    "        row_sub_sub_collection_member_list.append(member)\n",
    "        count_sub_sub_collection_member_dict[k] = len(row_sub_sub_collection_member_list)\n",
    "    column_sub_sub_collection_member_dict[k] = row_sub_sub_collection_member_list\n",
    "    row_sub_sub_collection_member_list =[]\n",
    "\n",
    "## Append the column member dictionary to the DigitalHub Community DF dataframe\n",
    "\n",
    "digitalhub_sub_sub_collection_recall_df['Member_List'] =digitalhub_sub_sub_collection_recall_df.index.map(column_sub_sub_collection_member_dict)\n",
    "digitalhub_sub_sub_collection_recall_df['Member_List_Count'] =digitalhub_sub_sub_collection_recall_df.index.map(count_sub_sub_collection_member_dict)\n",
    "digitalhub_sub_collection_recall_df.head()\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b2e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export file to excel, with the Pandas index, but with the header\n",
    "\n",
    "digitalhub_sub_sub_collection_recall_df.to_excel(\"outputs/digitalhub_sub_sub_collection_recall_df.xlsx\", index=True, header=True)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e395083",
   "metadata": {},
   "source": [
    "###### Split Recall Sub_Sub_Collection into Members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dc45a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a dataframe for each members row and concatenate all of these into one member_df\n",
    "\n",
    "sub_sub_collection_members_dfs_list = []\n",
    "\n",
    "for k, v in digitalhub_sub_sub_collection_recall_df[\"members\"].items():\n",
    "#     print(\"this is k: \", k)\n",
    "#     print(\"this is v: \", v)\n",
    "    sub_sub_collection_member_df = pd.json_normalize(v)\n",
    "    sub_sub_collection_member_df['sub_sub_collection_rowid'] = k\n",
    "    sub_sub_collection_members_dfs_list.append(sub_sub_collection_member_df)\n",
    "\n",
    "digitalhub_sub_sub_collection_members_df = pd.concat(sub_sub_collection_members_dfs_list, sort=False).reset_index(drop='index')\n",
    "digitalhub_sub_sub_collection_members_df.head()\n",
    "\n",
    "## Resource\n",
    "## https://stackoverflow.com/questions/62816027/convert-pandas-json-column-to-multiple-rows\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa8fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add Column to digitalhub_community_df to indicate that these results are a collection\n",
    "\n",
    "# digitalhub_sub_collection_df[\"Level\"] =  \"Collection\"\n",
    "\n",
    "digitalhub_sub_sub_collection_members_df['Level Type'] = np.where(digitalhub_sub_sub_collection_members_df['DOI'].isnull(),\"Sub_Sub_Sub_Collection\", \"Record\" )\n",
    "\n",
    "digitalhub_sub_sub_collection_members_df['Level Number'] = np.where(digitalhub_sub_sub_collection_members_df['DOI'].isnull(),\"4\", \"6\" )\n",
    "digitalhub_sub_sub_collection_members_df['Level Number'] = digitalhub_sub_sub_collection_members_df['Level Number'].apply(int)\n",
    "digitalhub_sub_sub_collection_members_df.head()\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ac5d09",
   "metadata": {},
   "source": [
    "##### Concatenate Recall Sub_Sub_Collection with Members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc22d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate the DigitalHub Sub_Sub_Collection_Recall Dataframe using the 'rowid' to the DigitalHub Sub_Sub_Collection Members Dataframe using the 'rowid'\n",
    "\n",
    "digitalhub_sub_sub_col_members_df = pd.concat([digitalhub_sub_sub_collection_recall_df, digitalhub_sub_sub_collection_members_df], axis=0).sort_values(by=['sub_sub_collection_rowid'])\n",
    "digitalhub_sub_sub_col_members_df.head()\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a559e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export file to excel, without the Pandas index, but with the header\n",
    "digitalhub_sub_sub_col_members_df.to_excel(\"outputs/digitalhub_sub_sub_col_members_df.xlsx\", index=False, header=True)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4786c0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort the dataframe by sub_sub_collection_rowid and Level Number to prepare for group by and forward fill of Sub_Sub_Collection_ID\n",
    "## sub_sub_collection_rowid then Level Number\n",
    "\n",
    "digitalhub_sub_sub_col_members_df.sort_values(by = ['sub_sub_collection_rowid','Level Number'], ascending = [True, True], inplace=True)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c2f172",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Groupby Sub_Sub_Collection_rowid and fill forward the Sub_Sub_Collection_ID into members of sub_sub_collections (i.e. sub_sub_sub_collections and records)\n",
    "\n",
    "digitalhub_sub_sub_col_members_df.update(digitalhub_sub_sub_col_members_df.groupby(['sub_sub_collection_rowid'])['Sub_Sub_Collection_ID'].ffill())\n",
    "\n",
    "## Resources\n",
    "## https://stackoverflow.com/questions/64795941/how-do-i-forward-fill-nas-with-condition-of-2-other-cells-being-equal-in-pandas\n",
    "## https://stackoverflow.com/questions/27012151/forward-fill-specific-columns-in-pandas-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f786ad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a column for Sub_Sub_Sub_Collection_ID to hold the Id from columns with Level Type as \"Sub_Sub_Sub_Collection\"\n",
    "\n",
    "digitalhub_sub_sub_col_members_df['Sub_Sub_Sub_Collection_ID'] = np.where(digitalhub_sub_sub_col_members_df['Level Type'] == 'Sub_Sub_Sub_Collection',digitalhub_sub_sub_col_members_df['Id'], np.nan)\n",
    "\n",
    "## Resources\n",
    "## https://stackoverflow.com/questions/67043249/how-to-use-np-where-in-creating-new-column-using-previous-rows\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11499442",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export file to excel, without the Pandas index with the header\n",
    "\n",
    "digitalhub_sub_sub_col_members_df.to_excel(\"outputs/digitalhub_sub_sub_col_members_df.xlsx\", header=True)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf667af",
   "metadata": {},
   "source": [
    "##### Concatenate Sub_Sub_Collection with Sub_Collection and Community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb6863",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate the DigitalHub digitalhub_sub_col_sub_col_df Dataframe using the 'Id' to the DigitalHub digitalhub_sub_sub_col_members_df Dataframe using the 'Id'\n",
    "#digitalhub_sub_col_sub_col_df\n",
    "#digitalhub_sub_sub_col_members_df\n",
    "\n",
    "digitalhub_sub_col_sub_col_sub_col_df = pd.concat([digitalhub_sub_col_sub_col_df, digitalhub_sub_sub_col_members_df], axis=0).sort_values(by=['Community_ID', 'Sub_Collection_ID'])\n",
    "digitalhub_sub_col_sub_col_sub_col_df.head()\n",
    "\n",
    "## Note: Creates duplicate rows for \"Sub_Sub_Collection_ID\"\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf8d0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export file to excel, without the Pandas index with the header\n",
    "\n",
    "digitalhub_sub_col_sub_col_sub_col_df.to_excel(\"outputs/digitalhub_sub_col_sub_col_sub_col_df.xlsx\", header=True)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead56289",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort the dataframe by Id and Level Number to get ready to groupby ID and remove duplicate Sub_Sub_Collections from the concatenate\n",
    "digitalhub_sub_col_sub_col_sub_col_df.sort_values(by = ['Id','Level Number'], ascending = [True, True], inplace=True)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72a7c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove duplicates for Sub_Sub_Collection ID between concatenated dataframes\n",
    "digitalhub_sub_col_sub_col_sub_col_df = digitalhub_sub_col_sub_col_sub_col_df.groupby(['Id'], as_index=False).first().reset_index()\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb2151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort the dataframe by Sub_Sub_Collection_ID and then Level Number to get ready to fill Community IDs into connected Sub_Sub_Collections\n",
    "\n",
    "digitalhub_sub_col_sub_col_sub_col_df.sort_values(by = ['Sub_Sub_Collection_ID','Level Number'], ascending = [True, True], inplace=True)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf11d089",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill foward the Community_ID into Records based on their Sub_Sub_Collection_IDs\n",
    "\n",
    "digitalhub_sub_col_sub_col_sub_col_df.update(digitalhub_sub_col_sub_col_sub_col_df.groupby(['Sub_Sub_Collection_ID'])['Community_ID'].ffill())\n",
    "\n",
    "## Other options\n",
    "##digitalhub_sub_col_sub_col_df['Community_ID'] = digitalhub_sub_col_sub_col_df.groupby(['Sub_Collection_ID'])['Community_ID'].fillna(method='ffill')\n",
    "##digitalhub_sub_col_sub_col_df['Community_ID'] = digitalhub_sub_col_sub_col_df.groupby(['Sub_Collection_ID'])['Community_ID'].transform(lambda x: x.ffill())\n",
    "##digitalhub_sub_col_sub_col_df['Community_ID'] = digitalhub_sub_col_sub_col_df.groupby(['Sub_Collection_ID'])['Community_ID'].fillna(method='ffill')\n",
    "\n",
    "## Resources\n",
    "## https://stackoverflow.com/questions/64795941/how-do-i-forward-fill-nas-with-condition-of-2-other-cells-being-equal-in-pandas\n",
    "## https://stackoverflow.com/questions/58181262/groupby-with-ffill-deletes-group-and-does-not-put-group-in-index\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6136a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export file to excel with the header\n",
    "\n",
    "digitalhub_sub_col_sub_col_sub_col_df.to_excel(\"outputs/digitalhub_sub_col_sub_col_sub_col_df.xlsx\",  header=True)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7735b057",
   "metadata": {},
   "source": [
    "#### Recal Sub_Sub_Sub_Collections\n",
    "##### Do not need if no sub_sub_sub_collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06451dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "\n",
    "## Extract a the Series for sub_sub_sub_collection \"dh_id\" and transform into a list\n",
    "\n",
    "digitalhub_sub_sub_sub_collection_series = digitalhub_sub_col_sub_col_sub_col_df[digitalhub_sub_col_sub_col_sub_col_df[\"Level Type\"] == \"Sub_Sub_Sub_Collection\"]['Id']\n",
    "digitalhub_sub_sub_sub_collection_list = digitalhub_sub_sub_sub_collection_series.tolist()\n",
    "\n",
    "print(digitalhub_sub_sub_sub_collection_list)\n",
    "\n",
    "## Checked: No problems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9034ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "\n",
    "## Loop through list of DigitalHub Sub_Sub_Sub_Collections and use the urllib.request to get the json data\n",
    "## test_list = ['2cc92425-b656-47ea-a3b4-825405ee6088', 'a86e1412-d72c-4cae-b8ca-16fd834cb128','fc389d13-2430-409b-82fd-a4b26613d350']\n",
    "\n",
    "# multi_digitalhub_sub_sub_sub_collection_list = []\n",
    "# digitalhub_sub_sub_sub_collection_problem_list = []\n",
    "\n",
    "# for item in digitalhub_sub_sub_sub_collection_list:\n",
    "#     try:\n",
    "\n",
    "#         with urllib.request.urlopen(f\"https://digitalhub.northwestern.edu/collections/{item}.json\" ) as url:\n",
    "#             single_digitalhub_sub_sub_sub_collection_dict = json.loads(url.read().decode())\n",
    "#             multi_digitalhub_sub_sub_sub_collection_list.append(single_digitalhub_sub_sub_sub_collection_dict)\n",
    "#             print(item)\n",
    "#         time.sleep(1)\n",
    "       \n",
    "\n",
    "#     except urllib.error.HTTPError as http_err:\n",
    "#         print(item)\n",
    "#         digitalhub_sub_sub_sub_collection_problem_list.append(item)\n",
    "#         print(f'HTTP error occurred: {http_err}')  # Python 3.6\n",
    "        \n",
    "\n",
    "#     except urllib.error.URLError as url_err:\n",
    "#         print(item)\n",
    "#         digitalhub_sub_sub_sub_collection_problem_list.append(item)\n",
    "#         print(f'URL error occurred: {url_err}. ')  # Python 3.6\n",
    "       \n",
    "\n",
    "#     except json.JSONDecodeError as json_err:\n",
    "#         print(item)\n",
    "#         digitalhub_sub_sub_sub_collection_problem_list.append(item)\n",
    "#         print(f'JSON Decode error occurred: {json_err}. ', 'Poorly formed JSON.')  # Python 3.6\n",
    "       \n",
    "        \n",
    "#     except Exception as err:\n",
    "#         print(item)\n",
    "#         digitalhub_sub_sub_sub_collection_problem_list.append(item)\n",
    "#         print(f'Other error occurred: {err}. ')  # Python 3.6\n",
    "        \n",
    "              \n",
    "#     else:\n",
    "#         print('Success!')\n",
    "\n",
    "\n",
    "\n",
    "## Resources\n",
    "## https://docs.python.org/3/library/urllib.request.html\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f95e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "\n",
    "## Inspect the results of the URL Query for DigitalHub Collections that will become communities in Prism\n",
    "\n",
    "# print(multi_digitalhub_sub_sub_sub_collection_list)\n",
    "# print(digitalhub_sub_sub_sub_collection_problem_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9a40a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "## Create a dataframe from DigitalHub json for DigitalHub Sub_Sub_Sub_Collections\n",
    "\n",
    "# digitalhub_sub_sub_sub_collection_recall_df = pd.DataFrame.from_dict(json_normalize(multi_digitalhub_sub_sub_sub_collection_list, max_level=1))\n",
    "# digitalhub_sub_sub_sub_collection_recall_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd60082",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "### DO NOT NEED if there are no problems with sub_sub_sub_collections\n",
    "\n",
    "## Upload .txt files of the problem Sub_Sub_Sub_Collection json metadata\n",
    "\n",
    "# name_here_path = r\"data\\sub_sub_sub_collection\\NAME HERE.txt\"\n",
    "# problem_sub_sub_sub_dict_list = []\n",
    "# path_sub_sub_list = [name_here_path]\n",
    "\n",
    "# for path in path_sub_sub_sub_list: \n",
    "#     with open(path, 'r', encoding= 'utf8') as f:\n",
    "#         s = f.read()\n",
    "#         while True:\n",
    "#             try:\n",
    "#                 result = json.loads(s)   # try to parse...\n",
    "#                 break                    # parsing worked -> exit loop\n",
    "#             except Exception as e:\n",
    "#                 # \"Expecting , delimiter: line 34 column 54 (char 1158)\"\n",
    "#                 # position of unexpected character after '\"'\n",
    "#                 unexp = int(re.findall(r'\\(char (\\d+)\\)', str(e))[0])\n",
    "#                 # position of unescaped '\"' before that\n",
    "#                 unesc = s.rfind(r'\"', 0, unexp)\n",
    "#                 s = s[:unesc] + r'\\\"' + s[unesc+1:]\n",
    "#                 # position of correspondig closing '\"' (+2 for inserted '\\')\n",
    "#                 closg = s.find(r'\"', unesc + 2)\n",
    "#                 s = s[:closg] + r'\\\"' + s[closg+1:]\n",
    "# #         print(result)\n",
    "#         problem_sub_sub_sub_dict_list.append(result)\n",
    "\n",
    "\n",
    "\n",
    "## https://stackoverflow.com/questions/16573332/jsondecodeerror-expecting-value-line-1-column-1-char-0\n",
    "## https://stackoverflow.com/questions/18514910/how-do-i-automatically-fix-an-invalid-json-string\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce29dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "### DO NOT NEED if there are no problems with sub_sub_sub_collections\n",
    "\n",
    "# problem_sub_sub_sub_df = pd.DataFrame.from_dict(json_normalize(problem_sub_sub_sub_dict_list, max_level=1))\n",
    "# problem_sub_sub_sub_df.head()\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3e22df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "### DO NOT NEED if there are no problems with sub_sub_sub_collections\n",
    "\n",
    "## Concatenate the DigitalHub Community Dataframe to the problem_df\n",
    "\n",
    "# digitalhub_sub_sub_sub_collection_recall_df= pd.concat([digitalhub_sub_sub_sub_collection_recall_df, problem_sub_sub_sub_df], axis=0)\n",
    "# digitalhub_sub_sub_sub_collection_recall_df.reset_index(inplace=True, drop=True) \n",
    "# digitalhub_sub_sub_sub_collection_recall_df.head(10)\n",
    "\n",
    "## Checked: No problems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d130c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "\n",
    "# ## Add Column to digitalhub_sub_sub_sub_collection_recall_df to indicate that these results are a sub_sub_sub_collection\n",
    "# digitalhub_sub_sub_sub_collection_recall_df[\"Level Type\"] = \"Sub_Sub_Sub_Collection\"\n",
    "# digitalhub_sub_sub_sub_collection_recall_df[\"Level Number\"] = \"4\"\n",
    "# digitalhub_sub_sub_sub_collection_recall_df['Level Number'] = digitalhub_sub_sub_sub_collection_recall_df['Level Number'].apply(int)\n",
    "\n",
    "# ## Create a column from the index\n",
    "# digitalhub_sub_sub_sub_collection_recall_df['sub_sub_sub_collection_rowid'] = digitalhub_sub_sub_sub_collection_recall_df.index\n",
    "\n",
    "# ## Create a new column called Sub_Collection_ID\n",
    "# digitalhub_sub_sub_sub_collection_recall_df['Sub_Sub_Sub_Collection_ID'] = digitalhub_sub_sub_sub_collection_recall_df['Id']\n",
    "\n",
    "# ## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693a77a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "# ## Inspect the \"members\" column and create a list of member IDs\n",
    "\n",
    "# row_sub_sub_sub_collection_member_list = []\n",
    "# column_sub_sub_sub_collection_member_dict ={}\n",
    "# count_sub_sub_sub_collection_member_dict = {}\n",
    "\n",
    "# for k, v in digitalhub_sub_sub_sub_collection_recall_df[\"members\"].items():\n",
    "#     for value in v: \n",
    "#         member = value[\"Id\"]\n",
    "#         row_sub_sub_sub_collection_member_list.append(member)\n",
    "#         count_sub_sub_sub_collection_member_dict[k] = len(row_sub_sub_sub_collection_member_list)\n",
    "#     column_sub_sub_sub_collection_member_dict[k] = row_sub_sub_sub_collection_member_list\n",
    "#     row_sub_sub_sub_collection_member_list =[]\n",
    "\n",
    "# ## Append the column member dictionary to the DigitalHub Community DF dataframe\n",
    "\n",
    "# digitalhub_sub_sub_sub_collection_recall_df['Member_List'] =digitalhub_sub_sub_sub_collection_recall_df.index.map(column_sub_sub_sub_collection_member_dict)\n",
    "# digitalhub_sub_sub_sub_collection_recall_df['Member_List_Count'] =digitalhub_sub_sub_sub_collection_recall_df.index.map(count_sub_sub_sub_collection_member_dict)\n",
    "# digitalhub_sub_sub_collection_recall_df.head()\n",
    "\n",
    "# ## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d1b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "# ## Export file to excel, without the Pandas index with the header\n",
    "\n",
    "# digitalhub_sub_sub_sub_collection_recall_df.to_excel(\"outputs/digitalhub_sub_sub_sub_collection_recall_df.xlsx\", header=True)\n",
    "\n",
    "# ## Checked: No problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa673ec",
   "metadata": {},
   "source": [
    "##### Split the Recall Sub_Sub_Sub_Collection into Members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c39126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "## Create a dataframe for each members row and concatenate all of these into one member_df\n",
    "\n",
    "# sub_sub_sub_collection_members_dfs_list = []\n",
    "\n",
    "# for k, v in digitalhub_sub_sub_sub_collection_recall_df[\"members\"].items():\n",
    "# #     print(\"this is k: \", k)\n",
    "# #     print(\"this is v: \", v)\n",
    "#     sub_sub_sub_collection_member_df = pd.json_normalize(v)\n",
    "#     sub_sub_sub_collection_member_df['sub_sub_sub_collection_rowid'] = k\n",
    "#     sub_sub_sub_collection_members_dfs_list.append(sub_sub_sub_collection_member_df)\n",
    "\n",
    "# digitalhub_sub_sub_sub_collection_members_df = pd.concat(sub_sub_sub_collection_members_dfs_list, sort=False).reset_index(drop='index')\n",
    "# digitalhub_sub_sub_sub_collection_members_df.head()\n",
    "\n",
    "# ## Resource\n",
    "# ## https://stackoverflow.com/questions/62816027/convert-pandas-json-column-to-multiple-rows\n",
    "\n",
    "# ## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef06af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "## Add Column to digitalhub_community_df to indicate that these results are a collection\n",
    "\n",
    "# digitalhub_sub_collection_df[\"Level\"] =  \"Collection\"\n",
    "\n",
    "# digitalhub_sub_sub_sub_collection_members_df['Level Type'] = np.where(digitalhub_sub_sub_sub_collection_members_df['DOI'].isnull(),\"Sub_Sub_Sub_Sub_Collection\", \"Record\" )\n",
    "\n",
    "# digitalhub_sub_sub_sub_collection_members_df['Level Number'] = np.where(digitalhub_sub_sub_sub_collection_members_df['DOI'].isnull(),\"5\", \"6\" )\n",
    "# digitalhub_sub_sub_sub_collection_members_df['Level Number'] = digitalhub_sub_sub_sub_collection_members_df['Level Number'].apply(int)\n",
    "# digitalhub_sub_sub_sub_collection_members_df.head()\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5566c5a1",
   "metadata": {},
   "source": [
    "##### Concatenate Reacal Sub_Sub_Sub_Collection with Members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee0704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "# ## Concatenate the DigitalHub Sub_Sub_Sub_Collection_Recall Dataframe using the 'rowid' to the DigitalHub Sub_Sub_Sub_Collection Members Dataframe using the 'rowid'\n",
    "\n",
    "# digitalhub_sub_sub_sub_col_members_df = pd.concat([digitalhub_sub_sub_sub_collection_recall_df, digitalhub_sub_sub_sub_collection_members_df], axis=0).sort_values(by=['sub_sub_sub_collection_rowid'])\n",
    "# digitalhub_sub_sub_sub_col_members_df.head()\n",
    "\n",
    "# ## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66f1900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "# ## Export file to excel, without the Pandas index, but with the header\n",
    "# digitalhub_sub_sub_sub_col_members_df.to_excel(\"outputs/digitalhub_sub_sub_sub_col_members_df.xlsx\", index=False, header=True)\n",
    "\n",
    "# ## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c9350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "# ## Sort the dataframe by sub_sub_sub_collection_rowid and Level Number to prepare for group by and forward fill of Sub_Sub_Sub_Collection_ID\n",
    "# ## sub_sub_sub_collection_rowid then Level Number\n",
    "\n",
    "# digitalhub_sub_sub_sub_col_members_df.sort_values(by = ['sub_sub_sub_collection_rowid','Level Number'], ascending = [True, True], inplace=True)\n",
    "\n",
    "# ## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e543385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "# ## Groupby Sub_Sub_Sub_Collection_rowid and fill forward the Sub_Sub_Sub_Collection_ID into members of sub_sub_sub_collections (i.e. sub_sub_sub_sub_collections and records)\n",
    "\n",
    "# digitalhub_sub_sub_sub_col_members_df.update(digitalhub_sub_sub_sub_col_members_df.groupby(['sub_sub_sub_collection_rowid'])['Sub_Sub_Sub_Collection_ID'].ffill())\n",
    "\n",
    "# ## Resources\n",
    "# ## https://stackoverflow.com/questions/64795941/how-do-i-forward-fill-nas-with-condition-of-2-other-cells-being-equal-in-pandas\n",
    "# ## https://stackoverflow.com/questions/27012151/forward-fill-specific-columns-in-pandas-dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009a8476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "# ## Create a column for Sub_Sub_Sub_Sub_Collection_ID to hold the Id from columns with Level Type as \"Sub_Sub_Sub_Sub_Collection\"\n",
    "\n",
    "# digitalhub_sub_sub_sub_col_members_df['Sub_Sub_Sub_Sub_Collection_ID'] = np.where(digitalhub_sub_sub_sub_col_members_df['Level Type'] == 'Sub_Sub_Sub_Sub_Collection',digitalhub_sub_sub_sub_col_members_df['Id'], np.nan)\n",
    "\n",
    "# ## Resources\n",
    "# ## https://stackoverflow.com/questions/67043249/how-to-use-np-where-in-creating-new-column-using-previous-rows\n",
    "\n",
    "# ## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7b0294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "# ## Export file to excel, without the Pandas index with the header\n",
    "\n",
    "# digitalhub_sub_sub_sub_col_members_df.to_excel(\"outputs/digitalhub_sub_sub_sub_col_members_df.xlsx\", header=True)\n",
    "\n",
    "# ## Checked: No problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412a5a8f",
   "metadata": {},
   "source": [
    "##### Concetenate Sub_Sub_Sub_Sub_Collection with Sub_Sub_Collection, Sub_Collection, and Community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3517f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "# ## Concatenate the DigitalHub digitalhub_sub_col_sub_col_df Dataframe using the 'Id' to the DigitalHub digitalhub_sub_sub_col_members_df Dataframe using the 'Id'\n",
    "# #digitalhub_sub_col_sub_col_df\n",
    "# #digitalhub_sub_sub_col_members_df\n",
    "\n",
    "# digitalhub_sub_col_sub_col_sub_col_sub_col_df = pd.concat([digitalhub_sub_col_sub_col_sub_col_df, digitalhub_sub_sub_sub_col_members_df], axis=0).sort_values(by=['Community_ID', 'Sub_Collection_ID'])\n",
    "# digitalhub_sub_col_sub_col_sub_col_sub_col_df.head()\n",
    "\n",
    "# ## Note: Creates duplicate rows for \"Sub_Sub_Collection_ID\"\n",
    "# ## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8471fb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "# ## Sort the dataframe by Id and Level Number to get ready to groupby ID and remove duplicate Sub_Sub_Sub_Collections from the concatenate\n",
    "# digitalhub_sub_col_sub_col_sub_col_sub_col_df.sort_values(by = ['Id','Level Number'], ascending = [True, True], inplace=True)\n",
    "\n",
    "# ## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e06f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "# digitalhub_sub_col_sub_col_sub_col_sub_col_df.drop(columns=['level_0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98952d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "# ## Remove duplicates for Sub_Sub_Sub_Collection ID between concatenated dataframes\n",
    "# digitalhub_sub_col_sub_col_sub_col_sub_col_df = digitalhub_sub_col_sub_col_sub_col_sub_col_df.groupby(['Id'], as_index=False).first().reset_index()\n",
    "\n",
    "# ## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62a1582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "# ## Sort the dataframe by Sub_Sub_Sub_Collection_ID and then Level Number to get ready to fill Community IDs into connected Sub_Sub_Sub_Collections\n",
    "\n",
    "# digitalhub_sub_col_sub_col_sub_col_sub_col_df.sort_values(by = ['Sub_Sub_Sub_Collection_ID','Level Number'], ascending = [True, True], inplace=True)\n",
    "\n",
    "# ## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8482d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "# ## Fill foward the Community_ID into Records based on their Sub_Sub_Sub_Collection_IDs\n",
    "\n",
    "# digitalhub_sub_col_sub_col_sub_col_sub_col_df.update(digitalhub_sub_col_sub_col_sub_col_sub_col_df.groupby(['Sub_Sub_Sub_Collection_ID'])['Community_ID'].ffill())\n",
    "\n",
    "# ## Other options\n",
    "# ##digitalhub_sub_col_sub_col_df['Community_ID'] = digitalhub_sub_col_sub_col_df.groupby(['Sub_Collection_ID'])['Community_ID'].fillna(method='ffill')\n",
    "# ##digitalhub_sub_col_sub_col_df['Community_ID'] = digitalhub_sub_col_sub_col_df.groupby(['Sub_Collection_ID'])['Community_ID'].transform(lambda x: x.ffill())\n",
    "# ##digitalhub_sub_col_sub_col_df['Community_ID'] = digitalhub_sub_col_sub_col_df.groupby(['Sub_Collection_ID'])['Community_ID'].fillna(method='ffill')\n",
    "\n",
    "# ## Resources\n",
    "# ## https://stackoverflow.com/questions/64795941/how-do-i-forward-fill-nas-with-condition-of-2-other-cells-being-equal-in-pandas\n",
    "# ## https://stackoverflow.com/questions/58181262/groupby-with-ffill-deletes-group-and-does-not-put-group-in-index\n",
    "\n",
    "# ## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319397e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "# ## Export file to excel with the header\n",
    "\n",
    "# digitalhub_sub_col_sub_col_sub_col_sub_col_df.to_excel(\"outputs/digitalhub_sub_col_sub_col_sub_col_sub_col_df.xlsx\",  header=True)\n",
    "\n",
    "# ## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9c6577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## DO NOT NEED if there are no sub_sub_sub_collections\n",
    "# digitalhub_sub_col_sub_col_sub_col_sub_col_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ee5ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If there are sub_sub_sub_collections, use: digitalhub_sub_col_sub_col_sub_col_sub_col_df\n",
    "## If there are no sub_sub_sub_collections, use: digitalhub_sub_col_sub_col_sub_col_df\n",
    "\n",
    "digitalhub_sub_col_sub_col_sub_col_df.drop(columns=['level_0', 'index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9379e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Re-order Columns\n",
    "## If there are sub_sub_sub_collections, use: digitalhub_sub_col_sub_col_sub_col_sub_col_df\n",
    "## If there are no sub_sub_sub_collections, use: digitalhub_sub_col_sub_col_sub_col_df\n",
    "\n",
    "re_ordered_df = digitalhub_sub_col_sub_col_sub_col_df.reindex(columns=['Level Type',\n",
    "                                                                               'Level Number', \n",
    "                                                                               'Community_ID',\n",
    "                                                                               'Sub_Collection_ID',\n",
    "                                                                               'Sub_Sub_Collection_ID',\n",
    "                                                                               'Sub_Sub_Sub_Collection_ID',\n",
    "                                                                               'Sub_Sub_Sub_Sub_Collection_ID',\n",
    "                                                                               'Record',\n",
    "                                                                               'Member_List',\n",
    "                                                                               'Member_List_Count',\n",
    "                                                                               'Title',\n",
    "                                                                               'uri',\n",
    "                                                                               'Id',\n",
    "                                                                               'Keyword',\n",
    "                                                                               'Resource type(s)',\n",
    "                                                                               'Rights',\n",
    "                                                                               'Creator',\n",
    "                                                                               'Contributor',\n",
    "                                                                               'Description',\n",
    "                                                                               'Abstract',\n",
    "                                                                               'Original Bibliographic Citation',\n",
    "                                                                               'Related ULR',\n",
    "                                                                               'Publisher',\n",
    "                                                                               'Date Created',\n",
    "                                                                               'Original Identifier',\n",
    "                                                                               'Language',\n",
    "                                                                               'Subject: MESH',\n",
    "                                                                               'Subject: LCSH',\n",
    "                                                                               'Subject: Geographic Name',\n",
    "                                                                               'Subject: Name',\n",
    "                                                                               'Location',\n",
    "                                                                               'Digital Origin',\n",
    "                                                                               'URI',\n",
    "                                                                               'Acknowledgements',\n",
    "                                                                               'Grants And Funding',\n",
    "                                                                               'DOI', \n",
    "                                                                               'ARK', \n",
    "                                                                               'File Size', \n",
    "                                                                               'File Format', \n",
    "                                                                               'download',\n",
    "                                                                               'Multi-page?',\n",
    "                                                                               'members',\n",
    "                                                                               'community_rowid',\n",
    "                                                                               'sub_collection_rowid',\n",
    "                                                                               'sub_sub_collection_rowid',\n",
    "                                                                               'sub_sub_sub_collection_rowid'\n",
    "                                                                              ])\n",
    "\n",
    "\n",
    "re_ordered_df.sort_values(by = ['Community_ID',\n",
    "                                'community_rowid', \n",
    "                                'Sub_Collection_ID', \n",
    "                                'sub_collection_rowid',\n",
    "                                'Sub_Sub_Collection_ID',\n",
    "                                'sub_sub_collection_rowid',\n",
    "                                'Sub_Sub_Sub_Collection_ID',\n",
    "                                'sub_sub_sub_collection_rowid',\n",
    "                                'Sub_Sub_Sub_Sub_Collection_ID'], ascending = [True, \n",
    "                                                                               True, \n",
    "                                                                               True, \n",
    "                                                                               True, \n",
    "                                                                               True, \n",
    "                                                                               True, \n",
    "                                                                               True, \n",
    "                                                                               True, \n",
    "                                                                               True], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08290b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_ordered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8ccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export file to excel with the header\n",
    "\n",
    "re_ordered_df.to_excel(\"outputs/re_ordered_df.xlsx\", index= False, header=True)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e10f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Upload a .csv DigitalHub Collections that will become Prism Communities\n",
    "\n",
    "digitalhub_community_path = \"data/2022_08-01 DigitalHub Collection Migration Plan_Communities Only.csv\"\n",
    "\n",
    "## Read the CSV file and store into Pandas DataFrame \n",
    "digitalhub_community_shape_df = pd.read_csv(digitalhub_community_path , encoding = \"ISO-8859-1\", na_values=['NULL', '<NA>'])\n",
    "\n",
    "## encoding = \"ISO-8859-1\", na_values=['NULL', '<NA>']\n",
    "\n",
    "#Change the column names to lower case with underscore for spaces\n",
    "digitalhub_community_shape_df.columns =  digitalhub_community_shape_df.columns.str.strip().str.lower().str.replace(\" \", \"_\").str.replace(\"(\",\"\").str.replace(\")\",\"\")\n",
    "digitalhub_community_shape_df.head()\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc731749",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge in fields from DigitalHub Communities spreadsheet\n",
    "#re_ordered_df\n",
    "#digitalhub_community_shape_df\n",
    "\n",
    "merged_df = re_ordered_df.merge(digitalhub_community_shape_df, how = 'left', left_on='Id', right_on='dh_id')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b447fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26112d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop extra columns\n",
    "\n",
    "drop_columns = ['ï»¿description','community','metadata:_title', 'metadata:_description', 'dh_id',\n",
    "           'number_of_collections', 'collection_name',       'child-collection_name_not_present_in_prism', \n",
    "           'number_of_items','item-level_id', 'item-level_doi', 'unnamed:_19']\n",
    "\n",
    "merged_df.drop(columns= drop_columns, inplace=True)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c292dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc05997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Final Re-order of columns\n",
    "\n",
    "## Re-order Columns\n",
    "## If there are sub_sub_sub_collections, use: digitalhub_sub_col_sub_col_sub_col_sub_col_df\n",
    "## If there are no sub_sub_sub_collections, use: digitalhub_sub_col_sub_col_sub_col_df\n",
    "\n",
    "final_re_ordered_df = merged_df.reindex(columns=['Level Type',\n",
    "                                                   'Level Number', \n",
    "                                                   'Community_ID',\n",
    "                                                   'Sub_Collection_ID',\n",
    "                                                   'Sub_Sub_Collection_ID',\n",
    "                                                   'Sub_Sub_Sub_Collection_ID',\n",
    "                                                   'Sub_Sub_Sub_Sub_Collection_ID',\n",
    "                                                   'Record',\n",
    "                                                   'Member_List',\n",
    "                                                   'Member_List_Count',\n",
    "                                                   'Title',\n",
    "                                                   'uri',\n",
    "                                                   'Id',\n",
    "                                                   'access:_visibility',\n",
    "                                                   'access:_member_policy', \n",
    "                                                   'access:_record_policy', \n",
    "                                                   'access:_owned_by', \n",
    "                                                   'access:_reader',\n",
    "                                                   'id', \n",
    "                                                   'metadata:_type', \n",
    "                                                   'metadata:_website'\n",
    "                                                   'Keyword',\n",
    "                                                   'Resource type(s)',\n",
    "                                                   'Rights',\n",
    "                                                   'Creator',\n",
    "                                                   'Contributor',\n",
    "                                                   'Description',\n",
    "                                                   'Abstract',\n",
    "                                                   'Original Bibliographic Citation',\n",
    "                                                   'Related ULR',\n",
    "                                                   'Publisher',\n",
    "                                                   'Date Created',\n",
    "                                                   'Original Identifier',\n",
    "                                                   'Language',\n",
    "                                                   'Subject: MESH',\n",
    "                                                   'Subject: LCSH',\n",
    "                                                   'Subject: Geographic Name',\n",
    "                                                   'Subject: Name',\n",
    "                                                   'Location',\n",
    "                                                   'Digital Origin',\n",
    "                                                   'URI',\n",
    "                                                   'Acknowledgements',\n",
    "                                                   'Grants And Funding',\n",
    "                                                   'DOI', \n",
    "                                                   'ARK', \n",
    "                                                   'File Size', \n",
    "                                                   'File Format', \n",
    "                                                   'download',\n",
    "                                                   'Multi-page?',\n",
    "                                                   'members',\n",
    "                                                   'community_rowid',\n",
    "                                                   'sub_collection_rowid',\n",
    "                                                   'sub_sub_collection_rowid',\n",
    "                                                   'sub_sub_sub_collection_rowid'\n",
    "                                                  ])\n",
    "\n",
    "final_re_ordered_df.rename(columns={'access:_visibility': 'Prism Visibility',\n",
    "                                       'access:_member_policy': 'Prism Member Policy', \n",
    "                                       'access:_record_policy': 'Prism Record Policy', \n",
    "                                       'access:_owned_by': 'Prism Owners', \n",
    "                                       'access:_reader': 'Prism Readers',\n",
    "                                       'id': 'Prism_Link', \n",
    "                                       'metadata:_type': 'Prism Community Type', \n",
    "                                       'metadata:_website': 'Prism Community Website'\n",
    "                                    })\n",
    "\n",
    "final_re_ordered_df.sort_values(by = ['Community_ID',\n",
    "                                'community_rowid', \n",
    "                                'Sub_Collection_ID', \n",
    "                                'sub_collection_rowid',\n",
    "                                'Sub_Sub_Collection_ID',\n",
    "                                'sub_sub_collection_rowid',\n",
    "                                'Sub_Sub_Sub_Collection_ID',\n",
    "                                'sub_sub_sub_collection_rowid',\n",
    "                                'Sub_Sub_Sub_Sub_Collection_ID'], ascending = [True, \n",
    "                                                                               True, \n",
    "                                                                               True, \n",
    "                                                                               True, \n",
    "                                                                               True, \n",
    "                                                                               True, \n",
    "                                                                               True, \n",
    "                                                                               True, \n",
    "                                                                               True], inplace=True)\n",
    "final_re_ordered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7ba00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export file to excel with the header\n",
    "\n",
    "final_re_ordered_df.to_excel(\"outputs/final_re_ordered_df.xlsx\", index= False, header=True)\n",
    "\n",
    "## Checked: No problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc87f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the results of the ROR API query\n",
    "\n",
    "with open(\"outputs/final_re_ordered_df_pickle\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(final_re_ordered_df, fp)\n",
    "\n",
    "with open(\"outputs/final_re_ordered_df_pickle\", \"rb\") as fp:   # Unpickling\n",
    "    final_re_ordered_df_pickle = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34774700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2452b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
